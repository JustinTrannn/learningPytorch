{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7d428c",
   "metadata": {},
   "source": [
    "# PyTorch Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415d9f3",
   "metadata": {},
   "source": [
    "## 0. Computer vision\n",
    "\n",
    "* [`torchvision`] (https://www.learnpytorch.io/03_pytorch_computer_vision/) - base domain library for PyTorch computer vision\n",
    "* `torchvision.datasets` - get datasets and data loading functions for your computer\n",
    "* `torchvision.models` - get pretrained computer vision models that you can leverage for you own problems\n",
    "* `torchvision.transforms` - functions for manipulating your vision data (images) to be suitable for use with an ML model\n",
    "* `torch.utils.data.Dataset` - Base dataset class for PyTorch\n",
    "* `torch.utils.data.DataLoaders` - Creates a Python iterable over a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8675e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "0.22.1+cu118\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision \n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check version\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8dfe0",
   "metadata": {},
   "source": [
    "### 1. Getting a dataset\n",
    "\n",
    "The dataset we'll be using is FashionMNIST from torchvision.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee63220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training data\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root='data', # where to download data to\n",
    "    train=True, # do we want the training dataset?\n",
    "    download=True, # do we want to download yes/no?\n",
    "    transform=ToTensor(), # how do we want to transform the data?\n",
    "    target_transform=None # how do we want to transform the labels/targets?\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23dcd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed318599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the first training example\n",
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd0fa860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070f9cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5bf072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "194412b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28]) -> [color_channels, height, width]\n",
      "Image label: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of out image\n",
    "image.shape, label\n",
    "print(f\"Image shape: {image.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image label: {class_names[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd2cd7",
   "metadata": {},
   "source": [
    "### 1.2 Visualizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cbabbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d7820e2bd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca529ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce5411dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows*cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61bdd56",
   "metadata": {},
   "source": [
    "Do you think these items of clothing could be modeled with pure linear lines? Or do you think we'll need non-linearities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "196ee0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bda215",
   "metadata": {},
   "source": [
    "## 2. Prepare DataLoader\n",
    "\n",
    "Right now, our data is in the form of PyTorch datasets.\n",
    "\n",
    "DataLoader turns our dataset into a python iterable.\n",
    "\n",
    "More specifically, we want to turn our data into batches (or mini-batches).\n",
    "\n",
    "1. It is more computationally efficient, as in, your computing hardware may not be able to look (store in memory) at 60000 images in one hit. So we break it down to 32 images at a time (batch size of 32).\n",
    "2. It gives our neural network more chances to update its gradients per epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9c0bb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1d782af98e0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1d7826d05c0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b0aeeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders: (<torch.utils.data.dataloader.DataLoader object at 0x000001D782AF98E0>, <torch.utils.data.dataloader.DataLoader object at 0x000001D7826D05C0>)\n",
      "Length of train_dataloader: 1875 batches of 32...\n",
      "Length of test_dataloader: 313 batches of 32...\n"
     ]
    }
   ],
   "source": [
    "# Let's checkout what we've created\n",
    "print(f\"DataLoaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
    "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a2b5737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkout what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b2d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "Label: 8, label size: torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEghJREFUeJzt3VmI3Wf5wPH3zD6ZTDK1aZMIranWJdIKapUgKrQWq1Z64YK1thCtKIhLxRtBqVYEo4gL2uaqtIhL64KCYl0uisulBXFDNMRIGKwxMUsz+5mMnAN9bP7C33kfnTfH6ecDoWk6T87vbPPt75yTJ521tbW1AgCllKELfQAADA5RACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIApvK/fffXzqdznk/Lr300nLttdeWhx566EIfHgy8kQt9ALARPvaxj5Urrrii9FZ7/fWvf+3H4jWveU357ne/W1772tde6MODgSUKbEqvfvWryzXXXBP/fvvtt5edO3eWr33ta6IA/w8vH/GkMDMzUyYnJ8vIyD//P+jTn/50eclLXlIuvvji/n974QtfWL75zW/+y+zCwkJ573vfW3bs2FGmp6fLTTfdVGZnZ/svTX30ox9tfE1gYzlTYFM6ffp0OX78eP/lo2PHjpUvfOEL5ezZs+XWW2+Nr/n85z/f/wb/lre8pSwvL5cHHnigvPGNbyzf+973yo033hhft3///vL1r3+93HbbbWXfvn3lJz/5yXn/HTaV3t+nAJvFfffd1/v7Qf7lx/j4+Nr9999/3tfOz8+f9+/Ly8trV1111dp1110Xv/bII4/05++4447zvnb//v39X//IRz6ywdcI2nKmwKZ09913l2c961n9n/feaP7yl79c3v72t/df/nnd617X//XeS0aPO3nyZFldXS0ve9nL+u87PO4HP/hB/5/vete7zvv93/Oe9/TfvIbNRhTYlF784hef90bzm9/85vL85z+/vPvd7+6/0Tw2NtZ/mejjH/94+eUvf1mWlpbia3vvFTzuz3/+cxkaGup/kumJrrzyykbXBNryRjNPCr1v7L0/q/CXv/yl/PGPfyw/+9nP+u8nTExMlHvuuad8//vfLz/+8Y/LLbfc0n8fAp6snCnwpNHtdvv/7L3h/K1vfasfhB/+8IdlfHw8vua+++47b+ZpT3taOXfuXPnTn/5UnvnMZ8avHzp0qOGRQzvOFHhSWFlZKT/60Y/6Lxvt3bu3DA8P918m6r2P8LgjR46U73znO+fN3XDDDf1/9s4mnqj3aSbYjJwpsCn1Vlr8/ve/7/+895HUr371q/2XjT74wQ+Wbdu29T9S+pnPfKa86lWv6r9k1Pua3pvTvfcKfvWrX8Xv0/uzC69//evL5z73uXLixIn4SOof/vCHf3n/ATYDUWBTuvPOO+PnvZeJnvOc55SDBw+Wd77znf1fu+6668q9995bDhw4UO64447+G8mf/OQn+2cLT4xCz5e+9KWya9eu/qeSvv3tb5frr7++PPjgg+XZz352//eGzaTT+1zqhT4I+F/T+8RS79NMvY+69v7wG2wW3lOAf6O35uL/6r2c1PtE08tf/vILckywUbx8BP/Gpz71qfLII4/0P9La253Ue7+i9+Md73hHueyyyy704cF/lZeP4N/o/fmFu+66q/zud7/rf5z18ssv7+9B+tCHPnTegj3YDEQBgOA9BQCCKAAQ1v2CqD+kw3+q92mdjN6aiVq9vxCnVu99glqZ9xR6f7lPRuaV3sxtnrm9+d+wnseQMwUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKANT/fQoW4vFEo6Oj1TMrKyupy7rhhhuqZ+68887qmS9+8YvVMzMzM9UzL33pS0vGJz7xieqZ3/zmN02W/HW73eoZ2rMQD4AqogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAECzEo9lyu1e84hUlY//+/dUzt912WxlUe/bsSc29733vq555//vfX1rIfH9Y57ce/ossxAOgiigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCM/POnbAaZbZWZjafT09PVM7fcckvJaLXxdGJionpmeHi4eubIkSMlY3Z2tnrm5ptvrp554IEHqmdGRkaaPO7YeM4UAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQLMTbZIaG6ju/urpaPfPhD3+4euYXv/hFaSWz3G5xcbF6ZsuWLaWVRx99tHrmRS96UZOFeJnldpnljT1ra2upOdbHmQIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIKFeANqeHg4NZdZbjcyUv8weMELXlA9c88995RWMrdDRrfbLa08/PDD1TM33nhj9cwll1xSPfO3v/2tyfLGnnPnzlXPWKK3fs4UAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKACw+RbidTqdJpeTWayVWfyVXRaWWQS3Z8+e6pmJiYnqmePHj5fN9njILGfLyiydu/TSS6tnbr311uqZz372s82W1GWfGy2Or5N83GUua6Mee84UAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKACw+RbitVpU12pxVctFa9u3b29yOS2v0yAvTctaXl6unhkZqX+KX3311WWzPR5YP2cKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogDA5tuSOshbGsfGxqpnRkdHU5c1NzdXPXPVVVdVz0xNTVXPLCwslFYWFxebXM7q6moZZPPz89UzO3fu3JBjeTKYmJgY6MfrejhTACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogDA4C7Em5mZSc195StfqZ75+c9/Xj3z9Kc/vXrmzJkz1TPT09MlY2iovvOTk5NNltu96U1vKhmzs7NNbofl5eUmy+N2795dMk6cOFFauOiii6pnPvCBDzRZFJl9bmRmxhLH9/e//71kHDp0qHrm3nvvLRvBmQIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAEJnbW1traxDp9MpLezatSs1d/DgweqZo0ePNll4tbS0VD2zZcuWknHxxRdXz4yOjlbPTE1NVc9cdtllJWOdD9H/eCZz33a73Sb3UfZ+OnXqVPXMyspK9Uzm+8Pi4mLJyDyfMssEO4nrtHXr1pKxbdu26pmbb755Q54XzhQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBGyoDZs2dPai6zvGrHjh3VMyMj9TfZ6upqk+VnPdu3b6+eOXbsWPXMr3/96yZL6rK3xeTkZJP7NnM5mYVu2QVyjz76aPXM4cOHq2euvvrqJs+LnnPnzlXP7N69u7Tw1Kc+NTV34MCBMiicKQAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAKGzts7VlZktpK985SurZ97whjeUjMzG06mpqeqZ48ePN9nyOTSU6/Xw8HCT7aCtjq3nzJkzpYXMYzxzP2W2fPZ0u93qmfHx8SaP18x1ym7NzZibm6uemZmZqZ7Ztm1byTh06FD1zO23374ht7kzBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoAhA3dhHb99ddXz9x9992py7rrrruaLEDbuXNnk8VfmaVkPWNjYwO7mCy75C+zmGx5ebnJ8rjsdcrIPF6XlpaaLN7LLFVcWVkpGZnnxurqapPLmUos2ex5xjOeUQaFMwUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKALRZiLd169bqmcOHD6cua9u2bU2WeGUWrS0uLlbPnDt3rmRkFqBt2bKlye3QavFez8LCQvXM3NxckyV6WZnbL/PYyyyqm5iYaLKkrmf79u1NFkWOJhbiPeUpTykZ3/jGN8qgcKYAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYA2C/EyC68ee+yx0kqn06meGR4ebrLIbH5+vmRklvxlFuJNTk42W4iXWb6XOb7MEsLMAsLsIriMzGVlZjL3UdbJkyebPPZGEwvxzp49WzKGhgbn/88H50gAuOBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQCgzUK8ljLL7TLLzC655JLqmR07djRbDJhZpJeZySzR63a7JSOzqC4zkzm+zALCzGM1u6guc3yZ2y6zcC5zbD0zMzPVM2NjY00eDxMTE+V/nTMFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQCgzZbUlhsDM1tFM5s+V1ZWmhzb0NBQsw2SmeuUkdm+2XP27Nkm1ylzfJnNpdn7dnR0tHpm+/bt1TPT09OlhezW3OXl5eqZubm5Jrf3dPK2O3LkSBkUzhQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoALD5FuKdPn26yfK4zAK0zEK3tbW1kjE/P99kEVzmvs0uCxsbG2uyAC1zO2SOLXs7ZBY4Zq5TZoFj5vnX6XSqZ7JzCwsL1TO7d++unllcXCwZP/3pT8ugcKYAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYA2C/EmJydLK6Ojo02Wzi0vL1fPbN26tdlCvKGhoSZL07rdbvXMyZMnS8b4+Hj1zMjISJPldpnb+8SJEyVjdna2yfMis3AucznDw8MlI3ObZx6vE4mlj5nll9n7dqM4UwAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQJuFeC1NTU1Vz2zZsqV6ZmFhockyrszSr+xyu8xM5vgyi9ayx5dZKDg3N1c9s7i4WFrJLAbMLPnL3E+D/njILOw7depU9czevXtLxrXXXls98/DDD5eN4EwBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBtFuI99thjpZWVlZUmS7Iy12l1dbV6ZmQkd9dkFsENDw8P9AK0zHVqJXNsmYVu2ftpaWmpyf3UaiY7l1l2OJr4/nD69OmSsX///uoZC/EA2HCiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGANltST506VVrJbEFstR00M9NyS2pm62T2+DK63W6Ty8lcp8wmzczm0ux21fHx8SaX03JbbKv7dijxvJ2fny8ZV155ZRkUzhQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABA2dKvZoUOHqmeuueaa1GX99re/rZ7Zt29fkyV6ExMTzZamZRa0Za5TZgHa6upq9Uz2sjJWVlaaLHVreTu0WgTXaib73BgbG2tyfGvJx+rs7GwZFM4UAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQOmvr3ODU6XRKCwcPHkzN7d27t8kys8zCuampqdLKmTNnmixoyy4zy8gsGcvMZB7jrY6t5XNw0I8t89jLHN9o4rk+OTlZMo4ePVo9c9NNN23IY8+ZAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAwkgZMGfPnk3N7dq1q3rm2LFj1TMzMzPVMyMj9TfzyspKybj88surZ6644orqmcOHD1fPLC8vV89k57JL51osE8wsYszOZRbBZWZaLanLyjwHO4njyzweWj5e18OZAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAMLhbUh988MHU3Nve9rbqmaNHj1bPLC0tNdlu+bznPa9kvPWtb62eeeihh5pspc3cdlnz8/PNtri22oiZmcvMZDaKjo2NNbmc7PbSbrfbZGY5+RgaHx8vg8KZAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAQmdtnRuzMkuoWtq3b1/1zEUXXVQ989znPrd6ZnJysskyrp4DBw6k5oDNbz3f7p0pABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQCgfiEeAJufMwUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAyuP+Aa33cJC8CROvAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a sample\n",
    "#torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.title(train_data.classes[label])\n",
    "plt.axis(False)\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bcb97b",
   "metadata": {},
   "source": [
    "## 3. Model 0: Build a baseline model\n",
    "\n",
    "When starting to build a series of machine learning modeling experiments, it's best practice to start with a baseline model.\n",
    "\n",
    "A baseline model is a simple model you will try and improve upon with subsequent models/experiments.\n",
    "\n",
    "In other words: start simply and add complexity when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa24cf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([1, 28, 28]) -> [color_channels, height, width]\n",
      "Shape after flattening: torch.Size([1, 784]) -> [color_channels, height*width]\n"
     ]
    }
   ],
   "source": [
    "# Create a flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "# Get a single sample\n",
    "x = train_features_batch[0]\n",
    "\n",
    "# Flatten the sample\n",
    "output = flatten_model(x) # perform forward pass\n",
    "\n",
    "# Print out what happened\n",
    "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a22d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0f42aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Setup model with input parameters\n",
    "model_0 = FashionMNISTModelV0(\n",
    "    input_shape=784, # The input shape has to be the the image height*width\n",
    "    hidden_units=10,\n",
    "    output_shape=len(class_names) # one for every class\n",
    ")\n",
    "\n",
    "model_0.to('cpu')\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b0ea330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0315,  0.3171,  0.0531, -0.2525,  0.5959,  0.2112,  0.3233,  0.2694,\n",
       "         -0.1004,  0.0157]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_x = torch.rand([1, 1, 28, 28]) # batch 1, color channel 1, height 28, width 28\n",
    "model_0(dummy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67b62e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer_stack.1.weight',\n",
       "              tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "                      [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "                      [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "                      ...,\n",
       "                      [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
       "                      [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
       "                      [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]])),\n",
       "             ('layer_stack.1.bias',\n",
       "              tensor([-0.0093,  0.0283, -0.0033,  0.0255,  0.0017,  0.0037, -0.0302, -0.0123,\n",
       "                       0.0018,  0.0163])),\n",
       "             ('layer_stack.2.weight',\n",
       "              tensor([[ 0.0614, -0.0687,  0.0021,  0.2718,  0.2109,  0.1079, -0.2279, -0.1063,\n",
       "                        0.2019,  0.2847],\n",
       "                      [-0.1495,  0.1344, -0.0740,  0.2006, -0.0475, -0.2514, -0.3130, -0.0118,\n",
       "                        0.0932, -0.1864],\n",
       "                      [ 0.2488,  0.1500,  0.1907,  0.1457, -0.3050, -0.0580,  0.1643,  0.1565,\n",
       "                       -0.2877, -0.1792],\n",
       "                      [ 0.2305, -0.2618,  0.2397, -0.0610,  0.0232,  0.1542,  0.0851, -0.2027,\n",
       "                        0.1030, -0.2715],\n",
       "                      [-0.1596, -0.0555, -0.0633,  0.2302, -0.1726,  0.2654,  0.1473,  0.1029,\n",
       "                        0.2252, -0.2160],\n",
       "                      [-0.2725,  0.0118,  0.1559,  0.1596,  0.0132,  0.3024,  0.1124,  0.1366,\n",
       "                       -0.1533,  0.0965],\n",
       "                      [-0.1184, -0.2555, -0.2057, -0.1909, -0.0477, -0.1324,  0.2905,  0.1307,\n",
       "                       -0.2629,  0.0133],\n",
       "                      [ 0.2727, -0.0127,  0.0513,  0.0863, -0.1043, -0.2047, -0.1185, -0.0825,\n",
       "                        0.2488, -0.2571],\n",
       "                      [ 0.0425, -0.1209, -0.0336, -0.0281, -0.1227,  0.0730,  0.0747, -0.1816,\n",
       "                        0.1943,  0.2853],\n",
       "                      [-0.1310,  0.0645, -0.1171,  0.2168, -0.0245, -0.2820,  0.0736,  0.2621,\n",
       "                        0.0012, -0.0810]])),\n",
       "             ('layer_stack.2.bias',\n",
       "              tensor([-0.0087,  0.1791,  0.2712, -0.0791,  0.1685,  0.1762,  0.2825,  0.2266,\n",
       "                      -0.2612, -0.2613]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745e8b3",
   "metadata": {},
   "source": [
    "### 3.1 Setup loss, optimizer and evaluation metrics\n",
    "\n",
    "* Loss function - since we're working with multi-class, our loss function will be `nn.CrossEntropyLoss()`\n",
    "* Optimizer - our optimizer `torch.optim.SGD()` (stochastic gradient descent)\n",
    "* Evaluation metric - since we're working on classification problem, let's use accuracy as our evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82d4f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Download helper functions from learn pytorch repo\n",
    "if Path('helper_functions.py').is_file():\n",
    "    print('helper_functions.py already exists, skipping download...')\n",
    "else:\n",
    "    print('Downloading helper_functions.py')\n",
    "    request = requests.get('https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py')\n",
    "    with open('helper_functions.py', 'wb') as f:\n",
    "        f.write(request.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4559d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy metric\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "# Setup loss functions and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f579b1",
   "metadata": {},
   "source": [
    "### 3.2 Creating a function to time our experiments\n",
    "\n",
    "Machine learning is very experimental.\n",
    "\n",
    "Two of the main things you'll often want to track are:\n",
    "1. Model's performance (loss and accuracy values)\n",
    "2. How fast it runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3b79dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float,\n",
    "                     end: float,\n",
    "                     device: torch.device=None):\n",
    "    '''\n",
    "    Prints difference between start and end time.\n",
    "    '''\n",
    "    total_time = end-start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "727c17ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on None: 0.000 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.030000127386302e-05"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timer()\n",
    "# code\n",
    "end_time = timer()\n",
    "print_train_time(start_time, end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de739764",
   "metadata": {},
   "source": [
    "### 3.3 Creating a training loop and training a model on batches of data\n",
    "\n",
    "1. Loop through epochs.\n",
    "2. Loop through training batches, perform training steps, calculate the train loss *per batch*.\n",
    "3. Loop through testing batches, perform testing steps, calculate the test loss *per batch*.\n",
    "4. Print out what's happening\n",
    "5. Time it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16e0f291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\justi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\justi\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 1/3 [00:11<00:22, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.5904 | Test loss: 0.5095, Test acc: 82.0387\n",
      "Epoch: 1\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 2/3 [00:20<00:10, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.4763 | Test loss: 0.4799, Test acc: 83.1969\n",
      "Epoch: 2\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [00:30<00:00, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.4550 | Test loss: 0.4766, Test acc: 83.4265\n",
      "Train time on cpu: 30.162 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm\n",
    "%pip install tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training time)\n",
    "epochs = 3\n",
    "\n",
    "# Create training and test loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "\n",
    "    # Training\n",
    "    train_loss = 0\n",
    "    # Add a loop to loop through the training batches\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "        # 1. Forward pass\n",
    "        y_pred = model_0(X)\n",
    "\n",
    "        # 2. Calculate the loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate train loss\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out what's happening\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    # Divide total train loss by length of train dataloader\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Testing loop\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            # 1. Forward pass\n",
    "            test_pred = model_0(X_test)\n",
    "\n",
    "            # 2. Calculate loss (accumlatively)\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "\n",
    "            # 3 Calculate accuarcy\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        # Calculate the test loss average per batch\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        # Calculate the test acc average per batch\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    # Print out what's happening\n",
    "    print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
    "\n",
    "# Calculate the training time\n",
    "train_time_end_on_cpu = timer()\n",
    "\n",
    "total_train_time_model_0 = print_train_time(train_time_start_on_cpu, train_time_end_on_cpu, device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b2c7a",
   "metadata": {},
   "source": [
    "### 4. Make predictions and get Model 0 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8a8320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 313/313 [00:01<00:00, 272.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.47663894295692444,\n",
       " 'model_acc': 83.42651757188499}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn) -> dict:\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing the results of model predicting on data_loader\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(data_loader):\n",
    "            # Make predictions\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate the lsos and acc values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # Scale the loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "# Calculate model 0 results on test dataset\n",
    "model_0_results = eval_model(model=model_0,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn)\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f81fb02",
   "metadata": {},
   "source": [
    "### 5. Setup device agnostic-code (for using a GPU if there is one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "564b194d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77514f5",
   "metadata": {},
   "source": [
    "#### My attempt at making the model and everything by myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "995184a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:00<00:00, 120.37it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "rows = 2\n",
    "cols = 2\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "for i in tqdm(range(1, rows*cols+1)):\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "\n",
    "    img, label = train_data[i]\n",
    "    plt.title(train_data.classes[label])\n",
    "    \n",
    "    plt.imshow(img.squeeze())\n",
    "    plt.axis(False)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              shuffle=True,\n",
    "                              batch_size=32)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=32,\n",
    "                             shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b5831f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 1/4 [00:10<00:30, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 80.41134185303514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 2/4 [00:20<00:20, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.20527156549521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 3/4 [00:30<00:10, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.26517571884985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:40<00:00, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 83.33666134185303\n",
      "Train time on cuda: 40.486 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40.486449600000924"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, n_in, n_out, n_hidden):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=n_in, out_features=n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=n_hidden, out_features=n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=n_hidden, out_features=n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=n_hidden, out_features=n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=n_hidden, out_features=n_out),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "    \n",
    "\n",
    "image, _ = train_data[0]\n",
    "_, height, width = image.shape\n",
    "\n",
    "# Initialize model, loss function and optimizer\n",
    "model_1 = FashionMNISTModelV1(n_in = height*width, n_out=len(train_data.classes), n_hidden=32)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.1)\n",
    "\n",
    "torch.manual_seed(77)\n",
    "start_time = timer()\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model_1.train()\n",
    "\n",
    "    for batch, (X_train, y_train) in enumerate(train_dataloader):\n",
    "        y_logits = model_1(X_train)\n",
    "        loss = loss_fn(y_logits, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out what's happening\n",
    "        # print(f\"Looked at {batch}/{len(train_dataloader)} batches\")\n",
    "\n",
    "    test_acc = 0\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X_test, y_test) in enumerate(test_dataloader):\n",
    "            test_logits = model_1(X_test)\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=torch.argmax(test_logits, dim=1))\n",
    "\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "end_time = timer()\n",
    "\n",
    "print_train_time(start=start_time, end=end_time, device=device)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c56745",
   "metadata": {},
   "source": [
    "### 6. Model 1: Building a better model with non-linearity\n",
    "\n",
    "Create a model with non-linear and linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8e31198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with non-linear and linear layers\n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1983bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = FashionMNISTModelV2(input_shape=784, # this is the output of the flatten after our 28*28 image goes in\n",
    "                              hidden_units=10,\n",
    "                              output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec7b2c2",
   "metadata": {},
   "source": [
    "### 6.1 Setup loss, optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "097d0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "loss_fn = nn.CrossEntropyLoss() # measure how wrong our model is\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1) # tries to update our model's parameters to reduce the loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e4195",
   "metadata": {},
   "source": [
    "### 6.2 Functionizing training and evaluation/testing loops\n",
    "\n",
    "Let's create a function for:\n",
    "* training loop -> `train_step()`\n",
    "* testing loop -> `test_step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7c580f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \"\"\"\n",
    "    Performs a training with model trying to learn on data_loader.\n",
    "    \"\"\"\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    # Add a loop to loop through the training batches\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Put data on target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate the loss and accuracy per batch\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate train loss\n",
    "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)) # go from logits to predcition labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # Divide total train loss and accuracy by length of train dataloader\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    \"\"\"\n",
    "    Performs a testing loop step on model going over data_loader.\n",
    "    \"\"\"\n",
    "    # Testing loop\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in data_loader:\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X_test)\n",
    "\n",
    "            # 2. Calculate loss (accumlatively)\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "\n",
    "            # 3 Calculate accuarcy\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1)) # raw logits -> prediction labels\n",
    "\n",
    "        # Calculate the test loss average per batch\n",
    "        test_loss /= len(data_loader)\n",
    "\n",
    "        # Calculate the test acc average per batch\n",
    "        test_acc /= len(data_loader)\n",
    "\n",
    "    # Print out what's happening\n",
    "    print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "816cd2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69206 | Train acc: 76.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 1/3 [00:25<00:50, 25.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.52792 | Test acc: 81.39%\n",
      "Train loss: 0.49743 | Train acc: 82.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 2/3 [00:41<00:19, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.49487 | Test acc: 82.59%\n",
      "Train loss: 0.46664 | Train acc: 83.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [00:57<00:00, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.49278 | Test acc: 82.92%\n",
      "Train time on cuda: 57.165 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.164848899999924"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and testing our model\n",
    "start_time = timer()\n",
    "epochs = 3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_step(model=model_2,\n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    \n",
    "    test_step(model=model_2,\n",
    "               data_loader=test_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    \n",
    "end_time = timer()\n",
    "total_train_time_model_2 = print_train_time(start=start_time, end=end_time, device=device)\n",
    "total_train_time_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b65b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.16222000000198\n",
      "57.164848899999924\n"
     ]
    }
   ],
   "source": [
    "print(total_train_time_model_0)\n",
    "print(total_train_time_model_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fa7dec",
   "metadata": {},
   "source": [
    "> **Note:** Sometimes, depending on your data/hardward you might find that your model trains faster on CPU than GPU.\n",
    ">\n",
    "> Why is this?\n",
    ">\n",
    "> 1. It could be that the overhead for copying data/model to and from the CPU outweighs the compute benefits offered by the GPU.\n",
    "> 2. The hardward you're using has a better CPU in terms compute capability than the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "541f7881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 313/313 [00:01<00:00, 170.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get model 1 results dictionary\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device=device) -> dict:\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing the results of model predicting on data_loader\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(data_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Make predictions\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate the lsos and acc values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # Scale the loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "model_2_results = eval_model(model=model_2,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn,\n",
    "                             device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efdd6ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'model_name': 'FashionMNISTModelV0',\n",
       "  'model_loss': 0.47663894295692444,\n",
       "  'model_acc': 83.42651757188499},\n",
       " {'model_name': 'FashionMNISTModelV2',\n",
       "  'model_loss': 0.4927782416343689,\n",
       "  'model_acc': 82.9173322683706})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_results, model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b74b5",
   "metadata": {},
   "source": [
    "## Model 3: Building a Convolutional Neural Network (CNN)\n",
    "\n",
    "CNN's are also known ConvNets.\n",
    "\n",
    "CNN's are known for their capabilities to find patterns in visual data\n",
    "\n",
    "This website is good to visualize how CNN's look - https://poloclub.github.io/cnn-explainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c109fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network\n",
    "class FashionMNISTModelV3(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture that replicates the TinyVGG model from the CNN explainer website\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                        out_channels=hidden_units,\n",
    "                        kernel_size=3,\n",
    "                        stride=1,\n",
    "                        padding=1), # values we can set ourselves in our NN's are called hyperparameters\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)          \n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*0, # there's a trick to calculating this\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv_block_2(x)\n",
    "        print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06dc52ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_3 = FashionMNISTModelV3(input_shape=1, # Our input shape is one because we have 1 color channel\n",
    "                              hidden_units=10,\n",
    "                              output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50217203",
   "metadata": {},
   "source": [
    "### 7.1 Stepping through `nn.Conv2d()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d767ae9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([32, 3, 64, 64])\n",
      "Single image shape: torch.Size([3, 64, 64])\n",
      "Test image:\n",
      " tensor([[[0.8823, 0.9150, 0.3829,  ..., 0.1587, 0.6542, 0.3278],\n",
      "         [0.6532, 0.3958, 0.9147,  ..., 0.2083, 0.3289, 0.1054],\n",
      "         [0.9192, 0.4008, 0.9302,  ..., 0.5535, 0.4117, 0.3510],\n",
      "         ...,\n",
      "         [0.1457, 0.1499, 0.3298,  ..., 0.9624, 0.6400, 0.7409],\n",
      "         [0.1709, 0.5797, 0.6340,  ..., 0.6885, 0.2405, 0.5956],\n",
      "         [0.9199, 0.1247, 0.3573,  ..., 0.6752, 0.2058, 0.5027]],\n",
      "\n",
      "        [[0.1458, 0.9024, 0.9217,  ..., 0.1868, 0.6352, 0.8431],\n",
      "         [0.9549, 0.4435, 0.6924,  ..., 0.1168, 0.7160, 0.5462],\n",
      "         [0.1616, 0.1054, 0.8614,  ..., 0.4531, 0.4736, 0.9448],\n",
      "         ...,\n",
      "         [0.4309, 0.3986, 0.1907,  ..., 0.9444, 0.2848, 0.3776],\n",
      "         [0.7948, 0.6855, 0.1009,  ..., 0.6147, 0.7747, 0.2323],\n",
      "         [0.5840, 0.9795, 0.3277,  ..., 0.3549, 0.1263, 0.1280]],\n",
      "\n",
      "        [[0.5027, 0.4195, 0.8893,  ..., 0.3084, 0.1567, 0.7860],\n",
      "         [0.7310, 0.9307, 0.2847,  ..., 0.8432, 0.8307, 0.0897],\n",
      "         [0.7021, 0.5967, 0.7744,  ..., 0.8485, 0.4520, 0.0401],\n",
      "         ...,\n",
      "         [0.5440, 0.0679, 0.6577,  ..., 0.9948, 0.2791, 0.4142],\n",
      "         [0.5095, 0.1246, 0.1726,  ..., 0.0984, 0.3224, 0.3125],\n",
      "         [0.3612, 0.8706, 0.4751,  ..., 0.5368, 0.2389, 0.2095]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "images = torch.rand(size=(32, 3, 64, 64))\n",
    "test_image = images[0]\n",
    "\n",
    "print(f\"Image batch shape: {images.shape}\")\n",
    "print(f\"Single image shape: {test_image.shape}\")\n",
    "print(f\"Test image:\\n {test_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76c374bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block_1.0.weight',\n",
       "              tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
       "                        [ 0.3062, -0.0730,  0.0673],\n",
       "                        [-0.1623,  0.1958,  0.2938]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2445,  0.2897,  0.0624],\n",
       "                        [ 0.2463,  0.0451,  0.1607],\n",
       "                        [-0.0471,  0.2570,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1556,  0.0850, -0.1536],\n",
       "                        [-0.0391, -0.1354,  0.2211],\n",
       "                        [-0.2631, -0.1537, -0.0941]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2004,  0.0315, -0.3292],\n",
       "                        [ 0.3010, -0.2832,  0.2573],\n",
       "                        [ 0.0555, -0.1082,  0.2060]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0520,  0.2693,  0.0364],\n",
       "                        [-0.1051,  0.0896, -0.0904],\n",
       "                        [ 0.1403,  0.2976,  0.1927]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1457,  0.1924,  0.0596],\n",
       "                        [ 0.1693, -0.2032, -0.3300],\n",
       "                        [-0.1288, -0.2557,  0.2735]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0960,  0.1381,  0.1054],\n",
       "                        [-0.0058,  0.2609, -0.2368],\n",
       "                        [ 0.0210, -0.2275,  0.1028]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1148,  0.1021, -0.0694],\n",
       "                        [ 0.2765, -0.1976, -0.1988],\n",
       "                        [-0.1988,  0.2998,  0.1111]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3208, -0.2751, -0.3306],\n",
       "                        [-0.2608, -0.2242,  0.1350],\n",
       "                        [ 0.1194,  0.2770, -0.1721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2272,  0.1769, -0.1347],\n",
       "                        [ 0.2023, -0.0791,  0.1907],\n",
       "                        [-0.2590, -0.1682,  0.1016]]]], device='cuda:0')),\n",
       "             ('conv_block_1.0.bias',\n",
       "              tensor([ 0.0705, -0.0850,  0.1987,  0.2266, -0.2417, -0.1780,  0.3052, -0.1125,\n",
       "                      -0.1182, -0.3225], device='cuda:0')),\n",
       "             ('conv_block_1.2.weight',\n",
       "              tensor([[[[-0.0604,  0.0263, -0.0139],\n",
       "                        [-0.0765,  0.0025, -0.0720],\n",
       "                        [-0.0894, -0.0580, -0.0923]],\n",
       "              \n",
       "                       [[-0.0671,  0.1054,  0.0199],\n",
       "                        [ 0.0325, -0.0983, -0.0692],\n",
       "                        [-0.0351,  0.0165, -0.0928]],\n",
       "              \n",
       "                       [[-0.0454, -0.0631,  0.0003],\n",
       "                        [-0.0392, -0.0073, -0.0714],\n",
       "                        [-0.0724, -0.0615, -0.0361]],\n",
       "              \n",
       "                       [[-0.0832,  0.0884, -0.0209],\n",
       "                        [ 0.0907,  0.0328, -0.0893],\n",
       "                        [ 0.0729, -0.0290, -0.0404]],\n",
       "              \n",
       "                       [[-0.0875, -0.1048,  0.0302],\n",
       "                        [-0.0230,  0.0410, -0.0865],\n",
       "                        [ 0.0783, -0.0774, -0.0182]],\n",
       "              \n",
       "                       [[ 0.0220,  0.0544,  0.0851],\n",
       "                        [ 0.0960, -0.0836,  0.0265],\n",
       "                        [-0.0453, -0.0116, -0.0789]],\n",
       "              \n",
       "                       [[ 0.0960, -0.0774,  0.0563],\n",
       "                        [ 0.0370,  0.0343, -0.0570],\n",
       "                        [ 0.0958,  0.0232,  0.0136]],\n",
       "              \n",
       "                       [[-0.0929,  0.0442, -0.0158],\n",
       "                        [-0.0483,  0.0905,  0.0235],\n",
       "                        [-0.0583, -0.0534, -0.0050]],\n",
       "              \n",
       "                       [[ 0.0589, -0.0269, -0.0601],\n",
       "                        [-0.0361, -0.0787,  0.0376],\n",
       "                        [ 0.0816, -0.0992,  0.0245]],\n",
       "              \n",
       "                       [[ 0.0545,  0.0191, -0.0375],\n",
       "                        [ 0.0550,  0.0554,  0.0394],\n",
       "                        [-0.0185, -0.0279,  0.0113]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0186, -0.0314,  0.0674],\n",
       "                        [ 0.0906, -0.0104, -0.0236],\n",
       "                        [ 0.0015, -0.0063,  0.0253]],\n",
       "              \n",
       "                       [[ 0.0295, -0.0957, -0.0389],\n",
       "                        [ 0.0888,  0.0411, -0.0052],\n",
       "                        [-0.0636, -0.0645, -0.0944]],\n",
       "              \n",
       "                       [[-0.0344,  0.0356,  0.0672],\n",
       "                        [ 0.0487, -0.0932, -0.0634],\n",
       "                        [-0.0166,  0.1020,  0.0152]],\n",
       "              \n",
       "                       [[-0.0273,  0.0436, -0.0401],\n",
       "                        [-0.0682,  0.0769, -0.0479],\n",
       "                        [-0.0211, -0.1049,  0.0705]],\n",
       "              \n",
       "                       [[ 0.0799,  0.0384, -0.0735],\n",
       "                        [-0.1040, -0.0856,  0.0786],\n",
       "                        [ 0.0506,  0.0887,  0.0552]],\n",
       "              \n",
       "                       [[ 0.0267, -0.0010, -0.0802],\n",
       "                        [-0.0903, -0.0986,  0.0432],\n",
       "                        [-0.0518, -0.0212, -0.0607]],\n",
       "              \n",
       "                       [[-0.0192, -0.0742, -0.0689],\n",
       "                        [ 0.0350, -0.0313,  0.0651],\n",
       "                        [-0.0338, -0.0773, -0.0186]],\n",
       "              \n",
       "                       [[-0.0511, -0.0322, -0.1003],\n",
       "                        [ 0.0590, -0.0734,  0.0530],\n",
       "                        [ 0.0478,  0.0753, -0.0809]],\n",
       "              \n",
       "                       [[ 0.0758, -0.0498,  0.0391],\n",
       "                        [ 0.0990, -0.0149, -0.0008],\n",
       "                        [-0.0243, -0.0880,  0.0506]],\n",
       "              \n",
       "                       [[-0.1046,  0.0654,  0.0789],\n",
       "                        [ 0.0997, -0.0249, -0.0866],\n",
       "                        [ 0.0237,  0.0582, -0.1049]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0239, -0.0632, -0.0092],\n",
       "                        [-0.0519, -0.0431, -0.0335],\n",
       "                        [-0.1002,  0.0865,  0.0884]],\n",
       "              \n",
       "                       [[-0.0165, -0.0120, -0.0430],\n",
       "                        [-0.0952, -0.1026,  0.0392],\n",
       "                        [-0.0579, -0.0678, -0.0082]],\n",
       "              \n",
       "                       [[-0.0351, -0.0341,  0.0034],\n",
       "                        [-0.0224, -0.0363, -0.0505],\n",
       "                        [-0.0858,  0.0884, -0.0422]],\n",
       "              \n",
       "                       [[ 0.0279, -0.0366,  0.0086],\n",
       "                        [ 0.0983,  0.0486, -0.0913],\n",
       "                        [ 0.0418,  0.1001,  0.0277]],\n",
       "              \n",
       "                       [[ 0.0707,  0.1039, -0.0162],\n",
       "                        [ 0.0219, -0.0733, -0.0217],\n",
       "                        [ 0.0781,  0.0540, -0.0667]],\n",
       "              \n",
       "                       [[-0.0845, -0.0720, -0.1040],\n",
       "                        [-0.0813, -0.0261,  0.0711],\n",
       "                        [ 0.0176, -0.0802, -0.0846]],\n",
       "              \n",
       "                       [[ 0.0524, -0.0784, -0.0130],\n",
       "                        [ 0.0506, -0.0488, -0.0115],\n",
       "                        [-0.0092, -0.0249, -0.0534]],\n",
       "              \n",
       "                       [[-0.0940, -0.0852, -0.0564],\n",
       "                        [ 0.1018, -0.0509, -0.0708],\n",
       "                        [ 0.0256,  0.0291,  0.0578]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0587, -0.1045],\n",
       "                        [ 0.0093,  0.0639, -0.0097],\n",
       "                        [-0.0621,  0.1005, -0.0394]],\n",
       "              \n",
       "                       [[-0.0600, -0.0950,  0.0047],\n",
       "                        [ 0.0467,  0.0233,  0.0208],\n",
       "                        [-0.0799, -0.0984,  0.0019]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0961,  0.0608, -0.0614],\n",
       "                        [-0.0137, -0.0777, -0.0509],\n",
       "                        [ 0.0191,  0.0574,  0.0873]],\n",
       "              \n",
       "                       [[-0.0968,  0.0705, -0.0743],\n",
       "                        [ 0.0395,  0.0892,  0.0015],\n",
       "                        [ 0.0959, -0.0898, -0.0403]],\n",
       "              \n",
       "                       [[ 0.0615, -0.0230, -0.0216],\n",
       "                        [-0.0439,  0.0727,  0.0517],\n",
       "                        [ 0.0338, -0.0592, -0.0856]],\n",
       "              \n",
       "                       [[ 0.0114,  0.0312, -0.0487],\n",
       "                        [-0.0295,  0.0712,  0.0084],\n",
       "                        [ 0.0048, -0.0259, -0.0955]],\n",
       "              \n",
       "                       [[-0.0991, -0.0504, -0.0536],\n",
       "                        [ 0.0328, -0.0307, -0.0412],\n",
       "                        [ 0.1005,  0.0367,  0.0751]],\n",
       "              \n",
       "                       [[-0.0510, -0.0431,  0.0387],\n",
       "                        [-0.0702, -0.0689, -0.0051],\n",
       "                        [-0.0386, -0.0790,  0.0625]],\n",
       "              \n",
       "                       [[ 0.0848,  0.0171, -0.0184],\n",
       "                        [-0.0976, -0.0384,  0.0268],\n",
       "                        [ 0.0497, -0.0133, -0.0417]],\n",
       "              \n",
       "                       [[ 0.0587, -0.0839,  0.0666],\n",
       "                        [-0.0409,  0.0016, -0.0208],\n",
       "                        [ 0.0128, -0.0319,  0.0766]],\n",
       "              \n",
       "                       [[-0.0027,  0.0823,  0.1013],\n",
       "                        [-0.0514, -0.0769,  0.0846],\n",
       "                        [ 0.0826, -0.0805, -0.0081]],\n",
       "              \n",
       "                       [[-0.1039, -0.0863,  0.0204],\n",
       "                        [ 0.0280,  0.0223, -0.0287],\n",
       "                        [ 0.0972,  0.0151, -0.0622]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0060,  0.0253,  0.0369],\n",
       "                        [-0.0745,  0.0395, -0.0539],\n",
       "                        [-0.0876, -0.0576,  0.1017]],\n",
       "              \n",
       "                       [[ 0.0901,  0.0944,  0.0619],\n",
       "                        [ 0.0796, -0.0141, -0.0580],\n",
       "                        [ 0.0527, -0.0546, -0.0711]],\n",
       "              \n",
       "                       [[-0.0337,  0.0221,  0.0543],\n",
       "                        [-0.0409, -0.0620,  0.0142],\n",
       "                        [-0.0621, -0.0686,  0.0549]],\n",
       "              \n",
       "                       [[-0.0177,  0.0963,  0.1025],\n",
       "                        [ 0.0315,  0.0363,  0.0243],\n",
       "                        [ 0.0017, -0.0077,  0.0014]],\n",
       "              \n",
       "                       [[ 0.0394,  0.0980, -0.0273],\n",
       "                        [-0.0446, -0.0255, -0.0509],\n",
       "                        [ 0.0179,  0.0787,  0.0824]],\n",
       "              \n",
       "                       [[ 0.0484, -0.0776, -0.0566],\n",
       "                        [-0.0232, -0.0194,  0.0087],\n",
       "                        [-0.0968,  0.0328, -0.0804]],\n",
       "              \n",
       "                       [[-0.0667, -0.0876,  0.0918],\n",
       "                        [-0.0998,  0.0795, -0.0035],\n",
       "                        [-0.0123,  0.0659, -0.0097]],\n",
       "              \n",
       "                       [[ 0.0661,  0.0762, -0.0915],\n",
       "                        [ 0.0406,  0.0199,  0.0227],\n",
       "                        [ 0.0154,  0.0288, -0.0507]],\n",
       "              \n",
       "                       [[-0.0135,  0.1002,  0.0708],\n",
       "                        [-0.0040, -0.0991,  0.0046],\n",
       "                        [-0.0718,  0.0857, -0.0640]],\n",
       "              \n",
       "                       [[-0.0076, -0.0234,  0.0188],\n",
       "                        [ 0.0992,  0.0100,  0.0610],\n",
       "                        [ 0.0818,  0.0851, -0.0364]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0236,  0.0508, -0.0288],\n",
       "                        [ 0.0494, -0.0230, -0.0715],\n",
       "                        [ 0.0429,  0.0162,  0.0470]],\n",
       "              \n",
       "                       [[ 0.1047,  0.0720,  0.0999],\n",
       "                        [ 0.0056, -0.0907, -0.0739],\n",
       "                        [-0.0655, -0.0929, -0.0528]],\n",
       "              \n",
       "                       [[-0.0970, -0.0973, -0.0630],\n",
       "                        [-0.1039, -0.0647,  0.0402],\n",
       "                        [ 0.0879, -0.0314, -0.0307]],\n",
       "              \n",
       "                       [[ 0.0563, -0.0520, -0.0498],\n",
       "                        [ 0.0649, -0.0918,  0.0129],\n",
       "                        [ 0.0931,  0.0181,  0.0287]],\n",
       "              \n",
       "                       [[-0.0614, -0.0015,  0.0058],\n",
       "                        [ 0.0259,  0.0410,  0.0916],\n",
       "                        [-0.0805,  0.0032, -0.0527]],\n",
       "              \n",
       "                       [[-0.0834, -0.0084, -0.0928],\n",
       "                        [ 0.0736,  0.0122, -0.0568],\n",
       "                        [ 0.0551, -0.0998, -0.0408]],\n",
       "              \n",
       "                       [[-0.0205, -0.0896, -0.0670],\n",
       "                        [-0.0172,  0.0800,  0.1018],\n",
       "                        [ 0.0671, -0.0629, -0.0690]],\n",
       "              \n",
       "                       [[ 0.0920,  0.0373,  0.0028],\n",
       "                        [ 0.0143, -0.0847, -0.0352],\n",
       "                        [ 0.1015, -0.0260, -0.0053]],\n",
       "              \n",
       "                       [[-0.0875, -0.0590, -0.0022],\n",
       "                        [-0.0655, -0.0131,  0.0429],\n",
       "                        [-0.1031,  0.0313, -0.0697]],\n",
       "              \n",
       "                       [[-0.0514,  0.0405,  0.0838],\n",
       "                        [-0.0288, -0.0433, -0.0953],\n",
       "                        [-0.0544, -0.0923, -0.0241]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0215, -0.0988,  0.0920],\n",
       "                        [ 0.0661, -0.1032, -0.0503],\n",
       "                        [ 0.0344, -0.0217, -0.0115]],\n",
       "              \n",
       "                       [[-0.0476,  0.0847, -0.0589],\n",
       "                        [ 0.0874,  0.0068,  0.0212],\n",
       "                        [ 0.0822, -0.0174, -0.0600]],\n",
       "              \n",
       "                       [[-0.0170,  0.0855, -0.0782],\n",
       "                        [ 0.0239, -0.1036,  0.0553],\n",
       "                        [ 0.0389,  0.0045,  0.0452]],\n",
       "              \n",
       "                       [[ 0.0001,  0.0583, -0.0834],\n",
       "                        [-0.0155,  0.0468,  0.1050],\n",
       "                        [ 0.0537, -0.0767,  0.0811]],\n",
       "              \n",
       "                       [[-0.0235, -0.0225, -0.0958],\n",
       "                        [-0.0166,  0.0746,  0.0147],\n",
       "                        [-0.0614,  0.0324, -0.0338]],\n",
       "              \n",
       "                       [[ 0.0962, -0.0915, -0.0333],\n",
       "                        [-0.1018, -0.0415,  0.0332],\n",
       "                        [ 0.1015,  0.0177,  0.1033]],\n",
       "              \n",
       "                       [[ 0.0206,  0.0609,  0.0845],\n",
       "                        [ 0.0881, -0.0590,  0.0969],\n",
       "                        [ 0.0639, -0.0493, -0.0503]],\n",
       "              \n",
       "                       [[-0.0884,  0.0265, -0.0854],\n",
       "                        [ 0.0445,  0.0333, -0.0916],\n",
       "                        [ 0.0287, -0.0086,  0.0482]],\n",
       "              \n",
       "                       [[ 0.0605, -0.1048,  0.0967],\n",
       "                        [ 0.0884,  0.0419, -0.0963],\n",
       "                        [-0.0377, -0.0305, -0.0271]],\n",
       "              \n",
       "                       [[ 0.0594,  0.0383,  0.0835],\n",
       "                        [-0.0395,  0.0355,  0.0375],\n",
       "                        [-0.0878, -0.1022, -0.0547]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0722, -0.0992, -0.0918],\n",
       "                        [ 0.0591,  0.0569,  0.0867],\n",
       "                        [-0.0796, -0.0771,  0.0541]],\n",
       "              \n",
       "                       [[ 0.0917,  0.0631,  0.0165],\n",
       "                        [ 0.0347,  0.1000, -0.0680],\n",
       "                        [-0.0479,  0.0737, -0.0721]],\n",
       "              \n",
       "                       [[-0.0581,  0.0769,  0.0333],\n",
       "                        [ 0.0341, -0.0447, -0.0015],\n",
       "                        [ 0.0965, -0.0633,  0.0008]],\n",
       "              \n",
       "                       [[ 0.0501, -0.0728,  0.1024],\n",
       "                        [-0.0527, -0.0253, -0.0285],\n",
       "                        [-0.0687, -0.1034,  0.0594]],\n",
       "              \n",
       "                       [[ 0.0280, -0.0987, -0.0678],\n",
       "                        [ 0.1042,  0.0403,  0.0423],\n",
       "                        [-0.0631, -0.0462, -0.0159]],\n",
       "              \n",
       "                       [[-0.0193, -0.0722,  0.0087],\n",
       "                        [ 0.0105, -0.0133,  0.0146],\n",
       "                        [-0.0418,  0.0274,  0.0398]],\n",
       "              \n",
       "                       [[-0.0555, -0.1045,  0.0552],\n",
       "                        [ 0.0251, -0.0536,  0.1016],\n",
       "                        [-0.0477,  0.0712,  0.0535]],\n",
       "              \n",
       "                       [[-0.0884,  0.0680, -0.0969],\n",
       "                        [-0.0584, -0.0176, -0.0711],\n",
       "                        [ 0.1030, -0.0211,  0.0419]],\n",
       "              \n",
       "                       [[-0.0941,  0.0607, -0.0328],\n",
       "                        [-0.0802,  0.0154,  0.0511],\n",
       "                        [ 0.0912, -0.0644, -0.0519]],\n",
       "              \n",
       "                       [[ 0.0203,  0.0286,  0.0405],\n",
       "                        [ 0.0579, -0.0239,  0.0586],\n",
       "                        [ 0.0777, -0.0275,  0.0750]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0515,  0.0930, -0.0599],\n",
       "                        [-0.0521, -0.0305,  0.0053],\n",
       "                        [ 0.0633, -0.0602,  0.0528]],\n",
       "              \n",
       "                       [[-0.0378,  0.0637, -0.0050],\n",
       "                        [-0.0923, -0.0580, -0.0763],\n",
       "                        [ 0.0523, -0.0707, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0227, -0.0578,  0.0304],\n",
       "                        [-0.1029, -0.0754, -0.0955],\n",
       "                        [-0.0319, -0.0384,  0.0151]],\n",
       "              \n",
       "                       [[-0.0195,  0.0496,  0.0966],\n",
       "                        [ 0.0378, -0.0415, -0.0987],\n",
       "                        [ 0.0382, -0.0522,  0.0536]],\n",
       "              \n",
       "                       [[ 0.0705,  0.0407,  0.0989],\n",
       "                        [ 0.1001,  0.0223, -0.0768],\n",
       "                        [ 0.0942, -0.0500, -0.0498]],\n",
       "              \n",
       "                       [[ 0.0882,  0.0817,  0.0318],\n",
       "                        [ 0.0066, -0.0887, -0.0109],\n",
       "                        [ 0.1011,  0.0268,  0.0090]],\n",
       "              \n",
       "                       [[-0.0219, -0.0368,  0.0628],\n",
       "                        [ 0.0065,  0.0686, -0.0187],\n",
       "                        [ 0.0461,  0.0435,  0.0168]],\n",
       "              \n",
       "                       [[ 0.0662,  0.0661,  0.0977],\n",
       "                        [ 0.0810, -0.0270, -0.0892],\n",
       "                        [ 0.0193, -0.0009, -0.0275]],\n",
       "              \n",
       "                       [[-0.0177,  0.0050,  0.0769],\n",
       "                        [ 0.0329, -0.0374, -0.0433],\n",
       "                        [-0.0261, -0.0407,  0.0948]],\n",
       "              \n",
       "                       [[ 0.0558,  0.0952,  0.0003],\n",
       "                        [ 0.0213,  0.0366, -0.0998],\n",
       "                        [ 0.0094, -0.0071, -0.0591]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0818,  0.0933,  0.0857],\n",
       "                        [ 0.0489,  0.1006, -0.0428],\n",
       "                        [-0.0182,  0.0399, -0.0174]],\n",
       "              \n",
       "                       [[-0.0207, -0.0871,  0.0283],\n",
       "                        [-0.0637,  0.0038,  0.1028],\n",
       "                        [-0.0324, -0.0332,  0.0636]],\n",
       "              \n",
       "                       [[-0.0388, -0.0091,  0.0984],\n",
       "                        [-0.0432, -0.0754, -0.0590],\n",
       "                        [-0.0292, -0.0500, -0.0547]],\n",
       "              \n",
       "                       [[ 0.0426,  0.0179, -0.0337],\n",
       "                        [-0.0819, -0.0332, -0.0445],\n",
       "                        [-0.0343, -0.0951,  0.0227]],\n",
       "              \n",
       "                       [[-0.0774, -0.0821, -0.0861],\n",
       "                        [ 0.0440, -0.0635, -0.0435],\n",
       "                        [ 0.0826,  0.0560,  0.0604]],\n",
       "              \n",
       "                       [[-0.1001, -0.0756, -0.0398],\n",
       "                        [ 0.0871,  0.0108, -0.0788],\n",
       "                        [ 0.0007, -0.0819, -0.0231]],\n",
       "              \n",
       "                       [[-0.0290,  0.0912,  0.0326],\n",
       "                        [-0.0184,  0.0178, -0.0304],\n",
       "                        [ 0.0414,  0.0417,  0.0283]],\n",
       "              \n",
       "                       [[-0.0411,  0.0899, -0.0152],\n",
       "                        [-0.0410,  0.0660,  0.0859],\n",
       "                        [ 0.1049,  0.0312, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0535,  0.0904, -0.1034],\n",
       "                        [-0.0131, -0.0719,  0.0196],\n",
       "                        [ 0.0436, -0.0218, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0474, -0.0177, -0.0885],\n",
       "                        [ 0.0843, -0.0531, -0.0116],\n",
       "                        [ 0.0099, -0.0063, -0.0992]]]], device='cuda:0')),\n",
       "             ('conv_block_1.2.bias',\n",
       "              tensor([ 0.0484, -0.0479, -0.0547,  0.0252, -0.0550, -0.0487, -0.0355, -0.0396,\n",
       "                      -0.0440, -0.0284], device='cuda:0')),\n",
       "             ('conv_block_2.0.weight',\n",
       "              tensor([[[[ 2.7393e-02, -8.5299e-02, -6.3802e-02],\n",
       "                        [ 1.5381e-03,  1.4659e-02,  5.8217e-02],\n",
       "                        [-7.4044e-02,  3.3646e-02,  5.9914e-02]],\n",
       "              \n",
       "                       [[ 5.8530e-02, -9.8180e-02, -4.0225e-02],\n",
       "                        [-9.0606e-02, -6.6704e-02,  5.8711e-02],\n",
       "                        [-1.5740e-02,  4.4769e-02, -6.1876e-02]],\n",
       "              \n",
       "                       [[ 1.6018e-02, -6.3758e-02,  5.2693e-02],\n",
       "                        [-4.6104e-02, -2.6432e-02, -9.1456e-02],\n",
       "                        [ 3.4823e-04,  1.0008e-01,  5.1163e-02]],\n",
       "              \n",
       "                       [[-5.6240e-02,  1.4176e-03, -1.1558e-02],\n",
       "                        [-8.4862e-02,  8.2650e-02,  1.6993e-03],\n",
       "                        [ 2.2199e-02, -4.2567e-02, -4.9323e-02]],\n",
       "              \n",
       "                       [[ 1.7381e-02,  3.8971e-02,  2.3643e-02],\n",
       "                        [-5.0801e-02,  1.0234e-01, -1.5517e-02],\n",
       "                        [-6.4554e-02, -4.9301e-02,  1.0377e-01]],\n",
       "              \n",
       "                       [[ 5.0738e-06, -1.4309e-02, -4.3867e-02],\n",
       "                        [-2.7633e-02, -8.8779e-02, -8.3767e-02],\n",
       "                        [ 6.1695e-02,  9.0172e-02,  1.0059e-01]],\n",
       "              \n",
       "                       [[-7.6099e-02,  5.7012e-02, -6.5245e-02],\n",
       "                        [ 6.2883e-02,  7.6058e-02,  8.1573e-02],\n",
       "                        [ 7.5900e-02,  6.5941e-02,  2.0517e-03]],\n",
       "              \n",
       "                       [[ 4.8434e-02, -3.7712e-02,  4.5899e-02],\n",
       "                        [-3.3879e-02, -1.7700e-03, -9.1746e-02],\n",
       "                        [-2.7562e-02, -5.5432e-02, -3.5557e-02]],\n",
       "              \n",
       "                       [[-6.7313e-02, -9.4810e-02,  6.8639e-03],\n",
       "                        [ 6.8408e-02,  9.6001e-02,  6.1512e-02],\n",
       "                        [-5.4638e-02, -1.0425e-01,  3.9983e-02]],\n",
       "              \n",
       "                       [[ 5.9062e-02, -9.0495e-02,  3.7798e-02],\n",
       "                        [ 8.9121e-02,  6.3853e-03, -6.3505e-02],\n",
       "                        [ 8.6423e-02,  4.5011e-02,  6.9802e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1287e-02,  6.1342e-02, -7.2002e-02],\n",
       "                        [ 1.0430e-01, -4.4662e-02,  6.3516e-02],\n",
       "                        [ 2.1107e-02,  2.7935e-02, -1.6165e-02]],\n",
       "              \n",
       "                       [[ 4.3295e-02, -4.3932e-02, -9.9357e-02],\n",
       "                        [-4.0499e-02,  8.2592e-02, -2.7751e-02],\n",
       "                        [ 3.3132e-02, -3.8973e-02,  7.9073e-02]],\n",
       "              \n",
       "                       [[ 6.3086e-02,  3.7211e-02, -5.3881e-02],\n",
       "                        [-8.6133e-02,  3.9686e-03, -6.1839e-02],\n",
       "                        [ 8.6667e-02, -1.0130e-01,  4.7104e-02]],\n",
       "              \n",
       "                       [[ 1.0508e-01,  5.2792e-02,  3.5942e-02],\n",
       "                        [-1.0142e-01,  1.0139e-01, -1.8030e-02],\n",
       "                        [-9.8495e-02,  1.0406e-01, -4.2894e-02]],\n",
       "              \n",
       "                       [[-7.4575e-03,  9.6479e-02, -7.3070e-02],\n",
       "                        [-7.4576e-02,  1.7141e-02, -1.4109e-02],\n",
       "                        [ 2.4280e-02, -8.8407e-02,  3.1524e-03]],\n",
       "              \n",
       "                       [[-4.6882e-02, -5.1820e-02, -9.6517e-02],\n",
       "                        [ 5.5890e-02,  2.0306e-02, -8.9118e-02],\n",
       "                        [ 8.3648e-02,  3.1794e-02,  1.9560e-02]],\n",
       "              \n",
       "                       [[-6.1890e-02,  1.5896e-02,  1.0157e-01],\n",
       "                        [ 7.2299e-02, -8.2100e-02,  9.6220e-02],\n",
       "                        [ 8.1702e-03,  5.0698e-02,  8.1869e-02]],\n",
       "              \n",
       "                       [[ 8.9862e-02, -8.2170e-02,  9.2303e-02],\n",
       "                        [-7.1591e-02,  7.9021e-03, -7.3656e-02],\n",
       "                        [-2.3109e-02, -4.7901e-03, -1.2611e-02]],\n",
       "              \n",
       "                       [[-1.6652e-02,  8.3137e-03,  1.0398e-01],\n",
       "                        [ 6.1244e-02,  5.8973e-02,  4.2190e-02],\n",
       "                        [ 8.1606e-02, -4.8645e-03,  8.3813e-03]],\n",
       "              \n",
       "                       [[ 2.1693e-02, -9.1931e-02, -8.4913e-02],\n",
       "                        [ 1.2923e-02, -4.1241e-02, -1.9342e-03],\n",
       "                        [-2.4187e-02,  1.6408e-02,  6.8581e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4958e-02,  8.4418e-02,  8.3227e-02],\n",
       "                        [-8.0901e-02, -8.1400e-02, -8.5284e-02],\n",
       "                        [-5.7766e-02, -4.1033e-02, -7.9341e-03]],\n",
       "              \n",
       "                       [[-2.5635e-02, -5.3258e-02, -3.3488e-02],\n",
       "                        [-3.8131e-02,  1.0341e-01, -3.9068e-02],\n",
       "                        [-7.5473e-02,  4.3818e-02, -6.0886e-03]],\n",
       "              \n",
       "                       [[ 8.0698e-02,  6.5863e-02,  9.6843e-02],\n",
       "                        [-7.7197e-02,  6.7764e-02,  8.8464e-02],\n",
       "                        [-5.2054e-02,  9.6890e-02,  7.9019e-02]],\n",
       "              \n",
       "                       [[ 1.1544e-03,  5.0823e-02, -3.6853e-02],\n",
       "                        [-9.1936e-02,  2.6645e-02,  3.1425e-02],\n",
       "                        [-6.8891e-02,  5.1123e-02, -9.0043e-02]],\n",
       "              \n",
       "                       [[ 9.0718e-02,  1.0208e-01,  2.8699e-02],\n",
       "                        [-6.6137e-02,  5.1300e-02,  1.7963e-02],\n",
       "                        [ 2.8663e-02,  3.4643e-02,  8.0254e-02]],\n",
       "              \n",
       "                       [[-4.5309e-02, -2.3711e-02,  2.8746e-02],\n",
       "                        [ 1.1486e-02,  8.5000e-02, -5.5365e-02],\n",
       "                        [-3.8387e-03,  1.9696e-02, -2.7996e-02]],\n",
       "              \n",
       "                       [[ 7.1859e-02,  1.1530e-02, -9.7422e-02],\n",
       "                        [-1.1420e-02, -4.7809e-02,  1.0243e-02],\n",
       "                        [-1.2250e-02, -1.0456e-01, -1.9208e-02]],\n",
       "              \n",
       "                       [[-1.0096e-02, -3.1083e-02,  9.6848e-02],\n",
       "                        [-2.3000e-02,  6.7717e-02,  2.6112e-02],\n",
       "                        [-8.8979e-02,  2.4770e-02,  8.7356e-02]],\n",
       "              \n",
       "                       [[-6.8948e-02, -6.8134e-02,  1.0318e-01],\n",
       "                        [ 8.4697e-02, -5.8807e-02,  6.3429e-02],\n",
       "                        [-1.3485e-02, -1.0393e-01,  7.9198e-03]],\n",
       "              \n",
       "                       [[ 3.4057e-02, -3.1619e-02,  3.6670e-02],\n",
       "                        [-9.0136e-02,  7.3050e-02,  8.9865e-02],\n",
       "                        [ 5.8130e-02,  1.7866e-02,  3.4716e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.6269e-02, -2.6339e-02, -1.0063e-02],\n",
       "                        [-5.8659e-02, -7.7857e-02,  7.0900e-02],\n",
       "                        [ 7.1535e-02, -9.5731e-02,  3.3542e-02]],\n",
       "              \n",
       "                       [[ 4.2881e-02,  1.0014e-01,  6.0985e-02],\n",
       "                        [ 9.6907e-02, -3.4510e-02,  7.3827e-02],\n",
       "                        [ 8.5740e-02, -9.9541e-02, -8.4613e-02]],\n",
       "              \n",
       "                       [[ 2.1335e-02,  5.7557e-02, -5.2369e-02],\n",
       "                        [ 1.1609e-02, -1.5303e-04,  2.6680e-02],\n",
       "                        [-5.6642e-02,  5.9455e-02,  7.0098e-02]],\n",
       "              \n",
       "                       [[-7.3139e-02,  1.0211e-03,  2.9247e-04],\n",
       "                        [ 3.3849e-02,  9.8198e-02,  3.0913e-02],\n",
       "                        [-2.3951e-02,  9.4672e-02, -4.0112e-02]],\n",
       "              \n",
       "                       [[-3.0608e-02,  7.1969e-03, -8.0270e-02],\n",
       "                        [ 1.1470e-02, -7.1518e-02,  1.0838e-02],\n",
       "                        [ 1.0099e-02,  1.4591e-02, -8.8891e-02]],\n",
       "              \n",
       "                       [[-1.0012e-01,  4.8501e-02,  9.0399e-02],\n",
       "                        [-9.3537e-02,  3.9043e-02, -7.7594e-02],\n",
       "                        [ 6.6082e-03,  9.8068e-02,  7.9965e-02]],\n",
       "              \n",
       "                       [[-7.7069e-02,  6.5203e-02,  5.5057e-02],\n",
       "                        [-1.6169e-04,  1.0211e-01, -4.1866e-02],\n",
       "                        [-2.4530e-02, -5.3275e-02,  1.5168e-02]],\n",
       "              \n",
       "                       [[ 2.7911e-02,  8.3990e-03, -5.9307e-02],\n",
       "                        [-4.7452e-02,  3.5855e-02, -9.2426e-02],\n",
       "                        [-1.6416e-02, -2.3350e-03, -4.2708e-02]],\n",
       "              \n",
       "                       [[ 3.8360e-02,  6.7940e-03,  7.4004e-02],\n",
       "                        [-9.3616e-03, -6.6528e-02,  7.4477e-02],\n",
       "                        [ 1.4720e-02, -3.0189e-02, -6.9476e-02]],\n",
       "              \n",
       "                       [[ 2.4707e-02, -1.0053e-01,  2.7762e-02],\n",
       "                        [ 5.2119e-02, -9.2465e-02, -6.9009e-02],\n",
       "                        [-7.5781e-02,  8.8597e-02,  8.9611e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5987e-03,  9.8959e-02, -3.5239e-02],\n",
       "                        [-1.0233e-01,  3.6819e-02,  3.7343e-02],\n",
       "                        [ 1.0334e-01, -3.0510e-05,  8.0785e-02]],\n",
       "              \n",
       "                       [[ 6.4612e-02,  7.6292e-02, -1.0460e-01],\n",
       "                        [ 8.6800e-02, -8.9856e-02,  9.4501e-02],\n",
       "                        [-4.3682e-03, -9.3415e-02,  2.9314e-02]],\n",
       "              \n",
       "                       [[-2.1456e-02, -9.4678e-02, -3.8215e-02],\n",
       "                        [ 1.0868e-02,  8.2098e-02, -3.2406e-02],\n",
       "                        [ 6.2610e-02,  1.3200e-02,  3.5531e-03]],\n",
       "              \n",
       "                       [[ 2.0170e-02, -6.9177e-02, -8.7616e-02],\n",
       "                        [-3.3121e-02, -9.8226e-02, -4.9158e-02],\n",
       "                        [ 4.8494e-03, -6.9424e-02, -4.3723e-02]],\n",
       "              \n",
       "                       [[-1.8941e-02, -1.2144e-02, -5.8187e-02],\n",
       "                        [ 5.0650e-03, -1.4795e-02,  3.0147e-02],\n",
       "                        [ 4.7611e-03, -5.2638e-02, -3.6291e-02]],\n",
       "              \n",
       "                       [[-1.2149e-03, -6.5774e-02,  8.2520e-03],\n",
       "                        [-7.4425e-03,  4.0897e-02,  2.4947e-02],\n",
       "                        [ 7.8887e-02, -3.4749e-03, -7.7887e-02]],\n",
       "              \n",
       "                       [[ 4.7119e-02, -7.1240e-02, -1.4489e-02],\n",
       "                        [-3.4132e-02, -3.9997e-02, -3.9000e-02],\n",
       "                        [ 9.6863e-02,  6.0342e-02,  2.9213e-02]],\n",
       "              \n",
       "                       [[ 9.8975e-02, -9.5524e-02,  1.7010e-02],\n",
       "                        [ 6.7481e-02,  7.0022e-02, -8.3890e-02],\n",
       "                        [ 3.7514e-02, -6.0050e-02, -4.1187e-03]],\n",
       "              \n",
       "                       [[-2.1996e-02, -8.8013e-02, -1.0055e-01],\n",
       "                        [-6.9349e-02,  4.7832e-02,  4.8218e-02],\n",
       "                        [-9.1681e-02, -3.9586e-02,  1.7218e-03]],\n",
       "              \n",
       "                       [[-9.1135e-02,  5.9393e-02,  9.5473e-02],\n",
       "                        [ 1.8643e-02, -7.8321e-02,  2.4580e-02],\n",
       "                        [ 3.8265e-02,  8.3468e-02, -5.6085e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.4437e-02,  4.6312e-02,  6.5624e-03],\n",
       "                        [-3.4345e-02, -4.4169e-02, -5.4351e-02],\n",
       "                        [ 8.5328e-02, -1.8187e-02,  7.6022e-02]],\n",
       "              \n",
       "                       [[ 9.4094e-02,  1.3353e-02,  2.2454e-02],\n",
       "                        [-7.1789e-03,  7.2397e-02, -9.4983e-02],\n",
       "                        [ 4.1919e-02, -1.7174e-02,  4.8132e-02]],\n",
       "              \n",
       "                       [[-4.6949e-04, -3.9029e-02, -1.1379e-02],\n",
       "                        [ 5.6920e-02, -7.3210e-02, -6.6629e-02],\n",
       "                        [-2.3611e-02, -3.8235e-02,  4.1409e-02]],\n",
       "              \n",
       "                       [[ 7.0937e-02, -1.1289e-02,  9.9672e-02],\n",
       "                        [-4.4042e-02, -5.9151e-02, -4.7191e-02],\n",
       "                        [-7.2624e-02, -7.3885e-02, -9.3921e-02]],\n",
       "              \n",
       "                       [[-9.3422e-02,  2.7512e-02,  6.4284e-02],\n",
       "                        [ 9.8963e-02,  8.9787e-02, -6.0709e-03],\n",
       "                        [ 2.0454e-02, -6.3068e-02,  4.0743e-02]],\n",
       "              \n",
       "                       [[-1.0107e-01,  4.9719e-02,  1.9334e-02],\n",
       "                        [ 3.2393e-02,  3.8595e-02, -4.8394e-02],\n",
       "                        [ 9.0452e-02,  5.0307e-02,  6.9243e-02]],\n",
       "              \n",
       "                       [[ 1.3922e-02,  6.6196e-02,  7.0941e-02],\n",
       "                        [ 4.7775e-02,  8.0297e-02, -1.9119e-02],\n",
       "                        [ 6.9310e-02,  2.4286e-02,  6.3424e-02]],\n",
       "              \n",
       "                       [[ 1.0267e-01,  2.3869e-02, -3.9124e-02],\n",
       "                        [-1.0488e-02,  2.9676e-02,  1.7773e-02],\n",
       "                        [-2.8795e-02,  8.2590e-02,  6.3331e-02]],\n",
       "              \n",
       "                       [[-6.5475e-02, -8.5889e-03, -1.0119e-02],\n",
       "                        [-6.6063e-02,  1.5374e-02, -3.2360e-02],\n",
       "                        [-5.4419e-02, -3.3894e-02, -3.7584e-02]],\n",
       "              \n",
       "                       [[ 1.0084e-01,  4.0432e-02,  1.0373e-01],\n",
       "                        [ 2.8903e-02,  2.3868e-02,  4.3333e-02],\n",
       "                        [ 1.8092e-02, -8.2722e-02, -6.2334e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5538e-02,  1.5846e-03,  3.9709e-02],\n",
       "                        [ 4.0588e-02,  8.3623e-02,  2.1458e-02],\n",
       "                        [-3.5975e-02, -7.9271e-02, -7.7203e-02]],\n",
       "              \n",
       "                       [[-6.2965e-02,  3.1792e-02,  5.6950e-02],\n",
       "                        [ 9.2224e-02, -3.3342e-02, -8.3150e-03],\n",
       "                        [-3.1303e-02, -3.8517e-04,  3.3837e-02]],\n",
       "              \n",
       "                       [[-2.3160e-03,  4.8799e-03,  1.3354e-02],\n",
       "                        [ 3.9256e-02, -3.1981e-02, -6.2855e-02],\n",
       "                        [ 2.4869e-02, -1.2481e-02, -4.7753e-02]],\n",
       "              \n",
       "                       [[ 4.4268e-02,  9.5597e-04, -1.5333e-02],\n",
       "                        [-5.1027e-02, -1.3868e-02, -8.9632e-02],\n",
       "                        [ 2.3980e-02,  1.5818e-03,  6.3966e-02]],\n",
       "              \n",
       "                       [[ 6.8063e-03,  8.4277e-03,  2.8715e-02],\n",
       "                        [ 8.0210e-02, -4.9812e-02,  6.2930e-02],\n",
       "                        [ 2.5779e-02, -7.0320e-02,  3.6702e-02]],\n",
       "              \n",
       "                       [[-6.3217e-02, -3.3181e-02, -5.0245e-02],\n",
       "                        [-7.1711e-02,  8.3017e-02, -9.4217e-02],\n",
       "                        [ 5.2706e-02, -9.4870e-02, -1.2829e-02]],\n",
       "              \n",
       "                       [[ 6.2868e-03,  7.4937e-02, -3.8147e-02],\n",
       "                        [ 3.0340e-02,  1.6329e-02,  6.2021e-02],\n",
       "                        [ 6.2668e-03,  3.9470e-02, -6.3677e-02]],\n",
       "              \n",
       "                       [[-7.3250e-02,  9.3928e-02, -7.6808e-02],\n",
       "                        [-1.7945e-02, -1.2742e-02,  1.0308e-01],\n",
       "                        [-2.2780e-02, -8.0249e-02, -2.6721e-02]],\n",
       "              \n",
       "                       [[ 5.4372e-02,  4.1773e-02,  8.7204e-02],\n",
       "                        [-2.1579e-02,  4.9653e-02, -9.9194e-02],\n",
       "                        [ 4.0787e-02,  4.8432e-02,  6.7998e-02]],\n",
       "              \n",
       "                       [[-6.0446e-02, -2.8142e-02,  2.5502e-02],\n",
       "                        [-7.4905e-02, -8.3851e-02, -1.0141e-01],\n",
       "                        [ 5.8842e-03,  6.5458e-02,  2.7075e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.4263e-03,  3.6727e-02, -6.6240e-02],\n",
       "                        [ 1.1113e-02, -2.6186e-02, -5.2193e-02],\n",
       "                        [ 9.0902e-02, -8.1550e-02,  1.5448e-02]],\n",
       "              \n",
       "                       [[-9.2624e-02, -3.5762e-03, -4.6840e-02],\n",
       "                        [ 3.4695e-02, -5.9191e-02,  6.7466e-02],\n",
       "                        [-8.5536e-02,  6.3313e-02, -7.9181e-02]],\n",
       "              \n",
       "                       [[ 5.6456e-02, -4.4384e-02, -2.4556e-04],\n",
       "                        [-1.9238e-02,  6.8414e-02,  3.4546e-02],\n",
       "                        [-9.2887e-02,  9.6914e-03, -7.2718e-02]],\n",
       "              \n",
       "                       [[ 7.8800e-02,  1.7319e-02, -2.7109e-02],\n",
       "                        [-5.3777e-02,  3.6485e-02, -6.3129e-02],\n",
       "                        [ 4.9992e-02,  5.7519e-02,  6.4701e-02]],\n",
       "              \n",
       "                       [[ 2.7537e-02, -9.2272e-02,  7.5823e-02],\n",
       "                        [-3.2700e-02, -3.1163e-02, -1.1325e-02],\n",
       "                        [ 7.7068e-02,  8.1052e-02,  1.6276e-02]],\n",
       "              \n",
       "                       [[ 5.0296e-02, -9.8241e-02,  2.4901e-04],\n",
       "                        [-9.3254e-02,  3.5876e-02, -7.5099e-02],\n",
       "                        [-3.7568e-02,  7.3684e-02,  1.0074e-01]],\n",
       "              \n",
       "                       [[-6.3286e-02, -5.8503e-02,  1.3055e-02],\n",
       "                        [ 4.1437e-02, -1.7168e-02, -3.2918e-02],\n",
       "                        [-6.9237e-02,  4.4997e-02,  1.0328e-01]],\n",
       "              \n",
       "                       [[-5.1026e-02,  4.9718e-02,  5.1481e-02],\n",
       "                        [ 8.4728e-02, -1.2001e-02,  3.3202e-03],\n",
       "                        [ 7.7444e-02,  6.6631e-02,  1.0411e-01]],\n",
       "              \n",
       "                       [[-3.0207e-02,  4.1709e-02,  7.3605e-02],\n",
       "                        [-7.1553e-02,  2.0940e-02, -2.3586e-02],\n",
       "                        [ 6.7760e-02, -4.7342e-02,  7.3933e-03]],\n",
       "              \n",
       "                       [[ 6.3067e-02, -9.6567e-02, -8.9004e-02],\n",
       "                        [-5.3989e-02,  6.7611e-02,  7.0680e-02],\n",
       "                        [-7.1991e-02,  2.0100e-02, -5.5854e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8926e-02,  9.0907e-02,  5.0914e-02],\n",
       "                        [-2.8828e-02,  1.5516e-02,  2.0424e-02],\n",
       "                        [ 2.4691e-02, -3.6079e-02, -6.2074e-02]],\n",
       "              \n",
       "                       [[ 6.9788e-02,  1.4164e-02,  4.4119e-02],\n",
       "                        [-3.9922e-02,  5.1057e-02,  7.6713e-02],\n",
       "                        [ 6.4107e-02,  2.8660e-02,  1.0371e-01]],\n",
       "              \n",
       "                       [[-2.3053e-04,  2.2441e-02,  1.0015e-01],\n",
       "                        [ 1.0245e-01, -4.4506e-02,  9.4953e-02],\n",
       "                        [ 3.8902e-02, -1.1799e-02,  9.2038e-02]],\n",
       "              \n",
       "                       [[-5.4605e-02,  6.8490e-02,  1.0445e-01],\n",
       "                        [-7.2701e-02, -6.2201e-02, -1.0445e-01],\n",
       "                        [-1.8970e-02, -9.5733e-02, -3.5304e-02]],\n",
       "              \n",
       "                       [[ 3.2002e-02,  7.4511e-02,  5.8717e-02],\n",
       "                        [ 5.8511e-02,  4.3730e-02, -6.5378e-02],\n",
       "                        [-8.3694e-02,  4.3696e-03,  1.0009e-01]],\n",
       "              \n",
       "                       [[ 5.9351e-03, -9.0662e-03, -7.1545e-02],\n",
       "                        [-5.2266e-02, -8.1256e-02,  8.4398e-02],\n",
       "                        [-1.7174e-02, -9.3119e-02,  1.1308e-02]],\n",
       "              \n",
       "                       [[ 7.6494e-03, -1.3023e-02,  3.7733e-02],\n",
       "                        [ 5.6687e-02, -9.9128e-02, -8.0753e-02],\n",
       "                        [-5.0639e-03, -9.7729e-02, -9.5750e-02]],\n",
       "              \n",
       "                       [[ 9.3067e-02, -8.0174e-03, -5.2113e-02],\n",
       "                        [-3.6157e-02, -8.2295e-02,  8.2258e-02],\n",
       "                        [-2.2857e-02, -5.9265e-02, -7.9944e-02]],\n",
       "              \n",
       "                       [[ 6.1611e-02, -1.4571e-02, -1.1074e-02],\n",
       "                        [-2.7473e-02, -5.0883e-02,  1.8751e-02],\n",
       "                        [ 8.1099e-02, -6.1093e-02,  5.0504e-03]],\n",
       "              \n",
       "                       [[-8.0165e-02, -4.9426e-02,  9.2525e-02],\n",
       "                        [ 1.1052e-03,  1.0154e-01, -1.8468e-02],\n",
       "                        [-5.7453e-02, -6.2981e-02,  9.3426e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.1058e-02,  5.5318e-02,  2.6203e-02],\n",
       "                        [ 3.1107e-02,  5.9476e-02, -2.7577e-02],\n",
       "                        [ 6.5223e-02, -8.3982e-02, -3.7087e-02]],\n",
       "              \n",
       "                       [[ 7.7164e-02,  3.1283e-02, -1.4038e-02],\n",
       "                        [-2.4616e-02, -6.4364e-02,  6.4098e-02],\n",
       "                        [-3.3520e-03, -3.5664e-03,  2.4929e-02]],\n",
       "              \n",
       "                       [[ 7.7787e-02, -5.3778e-02, -3.6303e-02],\n",
       "                        [ 7.1429e-02,  5.9532e-02, -5.1855e-02],\n",
       "                        [-1.0428e-01,  1.9555e-02,  5.5434e-02]],\n",
       "              \n",
       "                       [[ 2.5178e-02,  7.4768e-02, -8.3640e-02],\n",
       "                        [ 5.3156e-02, -6.5531e-02,  5.9325e-02],\n",
       "                        [ 7.8394e-02,  3.3385e-02,  8.5284e-02]],\n",
       "              \n",
       "                       [[-6.9481e-02, -9.4275e-02, -1.0135e-01],\n",
       "                        [ 6.6179e-02,  3.6926e-02, -7.7188e-02],\n",
       "                        [ 5.1048e-02,  9.6177e-02, -1.0394e-01]],\n",
       "              \n",
       "                       [[ 7.6466e-02,  1.6167e-02,  9.8053e-03],\n",
       "                        [ 9.4847e-02,  9.5458e-02,  4.4414e-02],\n",
       "                        [ 8.3288e-02,  4.3853e-02,  1.7176e-02]],\n",
       "              \n",
       "                       [[-9.2656e-02,  1.9689e-02, -7.4993e-02],\n",
       "                        [ 3.2452e-02,  1.8598e-02,  2.3681e-03],\n",
       "                        [-7.2071e-02, -6.3899e-02,  7.7912e-02]],\n",
       "              \n",
       "                       [[ 5.1336e-02,  5.5576e-02, -3.1410e-02],\n",
       "                        [-1.8151e-02, -2.7014e-02,  7.2489e-02],\n",
       "                        [-4.5504e-02,  6.6394e-02,  7.2679e-02]],\n",
       "              \n",
       "                       [[-9.6403e-02,  6.4369e-04, -2.0076e-02],\n",
       "                        [-5.8273e-02,  4.5507e-02, -1.2807e-02],\n",
       "                        [ 9.2287e-02, -6.5976e-02,  4.8976e-02]],\n",
       "              \n",
       "                       [[-8.9998e-02, -5.2833e-02,  7.1903e-03],\n",
       "                        [ 8.3283e-02,  5.5521e-02, -8.6550e-02],\n",
       "                        [ 1.1676e-02, -6.2138e-02,  4.5674e-03]]]], device='cuda:0')),\n",
       "             ('conv_block_2.0.bias',\n",
       "              tensor([-0.0878, -0.0309,  0.0723, -0.0967, -0.1005,  0.0192,  0.0144, -0.0193,\n",
       "                       0.0920, -0.0635], device='cuda:0')),\n",
       "             ('conv_block_2.2.weight',\n",
       "              tensor([[[[-6.3992e-02, -7.8791e-02, -1.9619e-02],\n",
       "                        [-2.6901e-02,  6.5222e-02, -5.9186e-03],\n",
       "                        [ 3.3663e-02, -4.3804e-02,  8.5507e-02]],\n",
       "              \n",
       "                       [[ 8.8862e-02, -9.4401e-02, -2.7090e-02],\n",
       "                        [-8.9439e-02,  4.4781e-02, -9.2094e-02],\n",
       "                        [-4.9839e-02,  1.0532e-01, -1.0066e-01]],\n",
       "              \n",
       "                       [[ 7.7771e-02,  8.9049e-03,  8.4289e-02],\n",
       "                        [-5.3494e-02,  6.9236e-02,  1.2718e-02],\n",
       "                        [ 8.1073e-03,  7.1945e-02, -1.0019e-01]],\n",
       "              \n",
       "                       [[-8.4902e-02,  1.0180e-01, -6.3298e-02],\n",
       "                        [-7.5980e-02, -5.1539e-03, -3.3742e-02],\n",
       "                        [-1.4421e-02, -7.0623e-02,  3.8034e-02]],\n",
       "              \n",
       "                       [[-9.0703e-02,  8.5374e-03,  6.1510e-02],\n",
       "                        [ 2.0253e-02,  1.4006e-02,  1.5418e-02],\n",
       "                        [-3.0880e-02, -2.0080e-02, -4.4450e-02]],\n",
       "              \n",
       "                       [[-7.1207e-02, -5.5810e-02,  1.0420e-01],\n",
       "                        [-1.7641e-02,  3.6924e-02,  7.2896e-02],\n",
       "                        [-8.2343e-03, -5.6707e-02, -7.1419e-02]],\n",
       "              \n",
       "                       [[-3.8833e-02,  3.7624e-02, -8.8771e-02],\n",
       "                        [-1.2870e-02,  4.0096e-02,  8.5999e-02],\n",
       "                        [ 3.1721e-02,  2.0846e-02,  7.2162e-02]],\n",
       "              \n",
       "                       [[ 4.8708e-02,  3.5661e-02, -3.2682e-02],\n",
       "                        [-8.4528e-02, -2.2769e-02, -1.9117e-02],\n",
       "                        [ 7.7410e-03, -1.1593e-02,  4.2616e-02]],\n",
       "              \n",
       "                       [[ 7.0050e-02, -4.2735e-02, -1.0002e-01],\n",
       "                        [-5.4081e-02, -5.0436e-02,  5.9750e-02],\n",
       "                        [-6.7994e-02, -9.9145e-03, -2.2340e-02]],\n",
       "              \n",
       "                       [[-6.3976e-02,  4.7780e-02, -4.3909e-02],\n",
       "                        [-5.4531e-03, -7.4112e-02, -1.0632e-02],\n",
       "                        [ 1.4977e-02, -4.2894e-03, -3.9386e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.1315e-02, -2.7311e-02, -5.8439e-02],\n",
       "                        [-7.7732e-02, -2.2329e-02, -9.9578e-02],\n",
       "                        [ 8.7492e-02, -5.0357e-02, -4.3684e-02]],\n",
       "              \n",
       "                       [[ 9.7439e-03,  2.7326e-02, -9.9393e-03],\n",
       "                        [ 7.2313e-02, -6.1448e-02,  3.7777e-02],\n",
       "                        [-2.3773e-04, -8.5747e-02, -4.0824e-02]],\n",
       "              \n",
       "                       [[ 2.6825e-02,  2.0138e-02,  7.6647e-02],\n",
       "                        [ 7.0518e-02, -5.7493e-02, -4.5013e-02],\n",
       "                        [-2.2351e-02, -7.5517e-02, -2.8459e-02]],\n",
       "              \n",
       "                       [[-8.6258e-02,  4.0092e-02,  7.4583e-02],\n",
       "                        [ 8.3459e-03, -7.5460e-02, -7.9827e-02],\n",
       "                        [-4.1036e-02,  3.0659e-02,  2.5711e-03]],\n",
       "              \n",
       "                       [[ 1.9166e-02,  9.9346e-02,  4.8956e-02],\n",
       "                        [ 2.2665e-02, -2.1327e-02,  4.9864e-02],\n",
       "                        [ 3.8563e-02, -9.4879e-02, -6.2266e-02]],\n",
       "              \n",
       "                       [[ 3.5381e-03,  3.9997e-02,  5.1282e-02],\n",
       "                        [-6.2748e-02, -1.0458e-01, -5.4909e-03],\n",
       "                        [-1.2050e-02,  3.0588e-02, -2.8988e-02]],\n",
       "              \n",
       "                       [[ 8.0588e-02,  7.0333e-03,  7.6975e-02],\n",
       "                        [-7.3398e-02,  4.2167e-02,  1.2560e-02],\n",
       "                        [-5.2720e-02,  5.2256e-02, -1.0372e-01]],\n",
       "              \n",
       "                       [[ 8.5220e-02,  8.4947e-03,  1.0178e-02],\n",
       "                        [ 4.8746e-02,  8.7503e-03,  4.5184e-02],\n",
       "                        [ 6.7063e-02, -8.2268e-02,  6.9735e-02]],\n",
       "              \n",
       "                       [[-1.5784e-02, -2.4513e-02,  2.1217e-02],\n",
       "                        [ 8.2446e-02, -5.7302e-02, -7.1039e-02],\n",
       "                        [ 6.5418e-02, -4.9507e-02,  3.3937e-02]],\n",
       "              \n",
       "                       [[-1.5530e-02,  2.9014e-02,  8.0439e-02],\n",
       "                        [-5.3421e-02, -5.1151e-02,  5.1716e-02],\n",
       "                        [ 5.7714e-03, -1.1601e-02, -9.2590e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9309e-02, -3.9919e-03, -1.9415e-02],\n",
       "                        [-4.3269e-02, -2.0801e-02,  5.1233e-02],\n",
       "                        [-2.4227e-03,  9.0147e-02, -6.0858e-03]],\n",
       "              \n",
       "                       [[-1.5122e-02,  5.9498e-02, -2.7275e-03],\n",
       "                        [-2.1039e-02,  3.5231e-02,  8.3129e-02],\n",
       "                        [ 2.6305e-02,  7.3398e-02,  6.8309e-02]],\n",
       "              \n",
       "                       [[ 2.9810e-02,  3.6650e-02,  3.4014e-02],\n",
       "                        [ 1.0934e-02,  8.9675e-02,  9.7308e-02],\n",
       "                        [ 3.7524e-02, -5.2640e-03,  9.4509e-02]],\n",
       "              \n",
       "                       [[-8.2042e-02,  7.7453e-02,  5.5849e-02],\n",
       "                        [ 6.7687e-02, -8.0992e-03, -7.8646e-02],\n",
       "                        [ 7.5193e-02, -4.6091e-02,  2.7734e-02]],\n",
       "              \n",
       "                       [[ 5.9719e-02, -9.8508e-02,  6.9954e-03],\n",
       "                        [-3.7444e-02,  7.4815e-02, -6.7114e-02],\n",
       "                        [ 6.4001e-02,  6.5730e-02,  5.8156e-02]],\n",
       "              \n",
       "                       [[ 1.0119e-01,  1.5964e-02, -9.5541e-02],\n",
       "                        [ 7.5248e-02,  9.6499e-03,  2.0918e-03],\n",
       "                        [-1.0041e-01, -2.3691e-02, -5.1162e-02]],\n",
       "              \n",
       "                       [[ 1.0324e-01,  7.5054e-02,  7.8634e-02],\n",
       "                        [ 7.2188e-02, -6.5340e-02, -4.5270e-02],\n",
       "                        [-4.1252e-02, -4.2257e-02,  8.2054e-02]],\n",
       "              \n",
       "                       [[ 3.5815e-02,  8.4470e-02, -4.9309e-03],\n",
       "                        [-9.3965e-02, -3.0582e-02,  7.4081e-02],\n",
       "                        [ 6.4174e-02,  3.2632e-02, -3.0919e-02]],\n",
       "              \n",
       "                       [[-9.8386e-02, -5.6639e-02,  5.4958e-02],\n",
       "                        [-4.2518e-02,  5.0421e-02,  2.8781e-02],\n",
       "                        [-4.0486e-02,  6.4202e-02, -3.3871e-02]],\n",
       "              \n",
       "                       [[-3.5020e-03, -4.0152e-02, -9.9988e-02],\n",
       "                        [ 1.6996e-02,  3.0460e-02, -5.3072e-02],\n",
       "                        [ 6.4663e-02, -9.4558e-02, -1.0161e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.5106e-02, -3.6430e-02, -1.1707e-02],\n",
       "                        [-2.0370e-02,  4.8108e-02, -9.2510e-02],\n",
       "                        [ 1.5521e-02,  1.8254e-03,  2.7842e-02]],\n",
       "              \n",
       "                       [[ 1.0479e-01,  6.4874e-02, -5.8366e-02],\n",
       "                        [-8.6378e-02, -2.5520e-02, -5.2876e-02],\n",
       "                        [ 3.6820e-02,  9.6628e-04,  8.4783e-02]],\n",
       "              \n",
       "                       [[ 4.1405e-02, -1.9382e-02,  3.6229e-03],\n",
       "                        [ 2.5244e-02, -1.3080e-02,  8.5058e-02],\n",
       "                        [-8.2420e-02,  5.1377e-02, -6.7192e-02]],\n",
       "              \n",
       "                       [[-9.2347e-02, -2.1640e-02,  5.1366e-02],\n",
       "                        [ 7.4478e-02,  2.6452e-02, -9.1104e-03],\n",
       "                        [-5.9092e-03, -4.2731e-02, -9.4592e-03]],\n",
       "              \n",
       "                       [[-7.2831e-03,  8.9699e-02,  6.1690e-02],\n",
       "                        [-8.4351e-02,  4.3605e-04, -6.4834e-02],\n",
       "                        [-1.6733e-02, -8.3776e-02,  2.7402e-02]],\n",
       "              \n",
       "                       [[-7.6008e-02,  1.0406e-01,  7.9605e-02],\n",
       "                        [-7.2559e-02, -9.9239e-02,  4.1128e-03],\n",
       "                        [-2.9425e-02,  3.0945e-02, -7.1353e-02]],\n",
       "              \n",
       "                       [[ 4.3148e-02, -9.1047e-02, -5.5632e-02],\n",
       "                        [-5.5414e-02,  5.1007e-02, -2.7597e-03],\n",
       "                        [-1.0130e-01, -6.0201e-02, -4.8781e-02]],\n",
       "              \n",
       "                       [[-9.7802e-02,  1.3497e-02,  3.7561e-02],\n",
       "                        [-1.9340e-02, -4.1947e-02, -6.3926e-04],\n",
       "                        [-8.3725e-02, -6.4184e-02, -2.4040e-03]],\n",
       "              \n",
       "                       [[ 9.3643e-02, -3.2414e-02,  5.2247e-02],\n",
       "                        [-4.1484e-02, -2.8060e-02, -1.0034e-01],\n",
       "                        [ 8.7330e-02,  1.0264e-01, -2.2139e-03]],\n",
       "              \n",
       "                       [[ 6.6974e-02,  8.6219e-02,  5.2359e-02],\n",
       "                        [ 5.4288e-02, -1.0035e-01, -9.9050e-02],\n",
       "                        [-8.0906e-02,  3.2970e-02, -9.1177e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.0464e-02, -5.1092e-02, -9.7154e-02],\n",
       "                        [ 1.4203e-04,  1.5207e-02, -6.1686e-02],\n",
       "                        [ 6.9018e-02, -4.0018e-02, -2.9676e-02]],\n",
       "              \n",
       "                       [[ 8.0309e-02,  9.0499e-02, -1.2093e-02],\n",
       "                        [-7.5671e-02, -5.2881e-02,  1.3423e-02],\n",
       "                        [ 6.1790e-02,  5.2477e-02, -4.6547e-02]],\n",
       "              \n",
       "                       [[-9.9650e-02, -9.2249e-02, -3.3537e-02],\n",
       "                        [ 1.3223e-03, -4.7347e-02, -8.3348e-02],\n",
       "                        [ 1.1109e-02, -8.3668e-02, -8.0946e-02]],\n",
       "              \n",
       "                       [[-8.5692e-02, -2.8563e-02,  9.3104e-02],\n",
       "                        [ 4.1207e-02, -1.2498e-02,  2.1694e-02],\n",
       "                        [ 4.1975e-02,  6.1414e-04, -8.5020e-02]],\n",
       "              \n",
       "                       [[-6.4944e-02, -7.1610e-02, -2.6766e-03],\n",
       "                        [-9.6492e-02, -1.9166e-02, -3.8545e-02],\n",
       "                        [ 1.0345e-01,  8.5679e-02,  6.1227e-02]],\n",
       "              \n",
       "                       [[ 5.9116e-03, -3.4129e-02,  2.6887e-02],\n",
       "                        [-7.2830e-02, -4.4957e-02, -2.1175e-02],\n",
       "                        [-2.4766e-02, -9.9854e-02,  4.1903e-02]],\n",
       "              \n",
       "                       [[ 8.6803e-02, -5.8141e-02,  2.8415e-02],\n",
       "                        [-1.2225e-02, -3.8445e-03,  6.1443e-03],\n",
       "                        [ 9.1346e-02,  1.4124e-02, -6.6690e-02]],\n",
       "              \n",
       "                       [[-3.7917e-02,  5.1495e-02,  3.2893e-02],\n",
       "                        [ 2.0487e-03, -1.3912e-02, -4.1012e-02],\n",
       "                        [-3.7413e-02, -5.5602e-02,  1.7273e-02]],\n",
       "              \n",
       "                       [[ 2.9603e-02,  8.0717e-02, -2.3813e-02],\n",
       "                        [ 7.5461e-03,  6.8125e-02,  4.5852e-02],\n",
       "                        [ 1.3544e-02,  3.2390e-02,  5.4714e-03]],\n",
       "              \n",
       "                       [[-9.0419e-02,  4.0636e-03, -2.3040e-02],\n",
       "                        [ 9.5123e-02,  9.5145e-02,  2.0912e-02],\n",
       "                        [ 9.4215e-02, -5.4288e-02,  9.1619e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.0756e-02, -4.0288e-03, -8.4592e-02],\n",
       "                        [-3.4015e-02, -2.8189e-02,  1.7411e-03],\n",
       "                        [-9.5569e-02,  1.9535e-02, -4.3839e-02]],\n",
       "              \n",
       "                       [[-2.6989e-02, -5.4443e-02, -2.2255e-02],\n",
       "                        [-9.7896e-02, -5.5885e-02,  9.7108e-03],\n",
       "                        [ 6.9072e-02,  9.5790e-02, -7.9737e-02]],\n",
       "              \n",
       "                       [[ 4.4264e-02, -5.9419e-02, -8.1498e-02],\n",
       "                        [-4.6417e-03, -6.0468e-02, -9.0783e-02],\n",
       "                        [-9.8509e-02, -7.0556e-02,  8.6619e-02]],\n",
       "              \n",
       "                       [[ 5.8788e-02, -4.1726e-02, -7.0553e-02],\n",
       "                        [-8.1085e-02, -6.2246e-02, -4.3376e-02],\n",
       "                        [ 6.3308e-02,  3.4496e-02, -4.0622e-02]],\n",
       "              \n",
       "                       [[ 7.2567e-02, -6.5484e-02, -8.5876e-02],\n",
       "                        [ 2.3006e-02, -5.8123e-02,  2.9987e-02],\n",
       "                        [ 8.9306e-02, -4.9849e-02, -7.3556e-02]],\n",
       "              \n",
       "                       [[ 3.9676e-02, -9.5200e-02,  9.4044e-02],\n",
       "                        [-4.9780e-02,  5.0961e-02, -8.3818e-02],\n",
       "                        [-7.1348e-02,  1.1611e-02,  3.7463e-02]],\n",
       "              \n",
       "                       [[ 8.1734e-02,  8.8158e-02, -6.0623e-03],\n",
       "                        [-1.3552e-02,  1.7424e-02, -2.4486e-02],\n",
       "                        [ 3.5882e-03, -9.9828e-02, -8.6531e-02]],\n",
       "              \n",
       "                       [[ 7.2233e-02, -6.1597e-02,  8.3008e-02],\n",
       "                        [ 1.1568e-02,  2.5676e-02,  9.5804e-02],\n",
       "                        [-5.8628e-02, -1.6640e-02,  1.8675e-02]],\n",
       "              \n",
       "                       [[ 3.6012e-02, -1.0259e-01,  3.7464e-02],\n",
       "                        [-6.2163e-02,  1.3846e-02,  7.1315e-02],\n",
       "                        [-1.0500e-02, -3.3346e-03, -7.8757e-03]],\n",
       "              \n",
       "                       [[ 8.7962e-02,  5.9907e-02,  1.7727e-02],\n",
       "                        [-6.3437e-02, -5.7241e-02,  8.3964e-02],\n",
       "                        [ 7.5834e-02,  6.1033e-02, -8.2189e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.2092e-02, -1.0076e-02,  7.7661e-02],\n",
       "                        [ 9.1553e-02,  1.1554e-02, -4.3863e-02],\n",
       "                        [ 9.9153e-02, -5.4931e-02,  6.8876e-02]],\n",
       "              \n",
       "                       [[-1.0108e-01, -3.3153e-02, -9.1902e-02],\n",
       "                        [-4.7284e-02,  4.4759e-02, -7.5529e-02],\n",
       "                        [-9.1158e-02,  7.5371e-02,  5.6270e-02]],\n",
       "              \n",
       "                       [[-1.1527e-03, -7.4309e-02, -2.7927e-02],\n",
       "                        [-3.4129e-02,  6.5100e-02, -3.4478e-02],\n",
       "                        [-3.0360e-02, -7.4720e-02, -4.9646e-02]],\n",
       "              \n",
       "                       [[ 5.7074e-02,  6.7914e-02,  1.5315e-02],\n",
       "                        [-3.9549e-02,  1.0124e-01,  2.0806e-02],\n",
       "                        [-4.0688e-02, -3.6535e-02, -1.4752e-02]],\n",
       "              \n",
       "                       [[ 4.9974e-02,  3.8555e-02,  7.6418e-02],\n",
       "                        [-4.7494e-03,  8.7183e-02, -4.2816e-02],\n",
       "                        [-4.8547e-02, -3.8927e-02, -9.8896e-02]],\n",
       "              \n",
       "                       [[-6.9195e-02, -9.5382e-02, -6.2294e-03],\n",
       "                        [ 9.9374e-04, -2.7358e-02, -7.2035e-02],\n",
       "                        [ 9.5637e-02, -3.4926e-02,  5.0233e-02]],\n",
       "              \n",
       "                       [[ 7.3408e-02, -6.9292e-02, -1.3179e-02],\n",
       "                        [ 6.0923e-02,  1.0218e-01, -1.3299e-02],\n",
       "                        [ 7.6382e-02, -8.2732e-02, -6.8489e-02]],\n",
       "              \n",
       "                       [[ 8.6682e-02, -9.9801e-03,  1.0414e-01],\n",
       "                        [ 7.6651e-03, -4.3714e-02,  1.0011e-01],\n",
       "                        [ 9.2179e-02,  9.7826e-03, -6.3900e-02]],\n",
       "              \n",
       "                       [[-4.5639e-03, -5.0693e-02,  7.6810e-02],\n",
       "                        [ 4.8829e-03,  2.2191e-02,  6.3927e-02],\n",
       "                        [ 3.4916e-02, -6.5803e-02,  8.7566e-02]],\n",
       "              \n",
       "                       [[ 6.4758e-02, -6.5073e-02,  7.9700e-02],\n",
       "                        [ 2.9905e-02, -2.0750e-02, -7.5385e-02],\n",
       "                        [-1.7490e-02, -1.0335e-01,  6.0163e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.6343e-02, -3.0347e-02,  9.7720e-02],\n",
       "                        [-3.9032e-02,  1.8051e-02, -7.3459e-02],\n",
       "                        [-4.4565e-03,  4.2610e-02,  4.5403e-02]],\n",
       "              \n",
       "                       [[-3.5346e-03, -5.3154e-02,  7.3680e-02],\n",
       "                        [ 6.9788e-02,  1.6916e-02, -4.8475e-02],\n",
       "                        [ 2.2349e-02,  2.8186e-04,  9.6302e-02]],\n",
       "              \n",
       "                       [[ 1.5621e-02,  8.1301e-03,  7.2057e-03],\n",
       "                        [ 5.6079e-02, -1.3024e-03,  9.0351e-02],\n",
       "                        [ 5.4917e-02, -7.9650e-02, -1.2070e-06]],\n",
       "              \n",
       "                       [[-8.9472e-02, -8.0934e-02,  2.0480e-02],\n",
       "                        [ 2.3687e-02, -9.2246e-03,  1.0019e-01],\n",
       "                        [-5.6627e-02, -4.4176e-02, -1.6881e-02]],\n",
       "              \n",
       "                       [[ 6.3911e-04, -8.9284e-03,  9.4909e-02],\n",
       "                        [-4.4519e-02, -5.5137e-02,  9.0599e-03],\n",
       "                        [ 7.9171e-02,  2.5019e-02,  5.6787e-02]],\n",
       "              \n",
       "                       [[ 2.0406e-02,  8.9839e-02,  6.3311e-02],\n",
       "                        [ 7.5428e-02, -1.4198e-02, -8.7268e-02],\n",
       "                        [-5.0002e-02,  3.5910e-02,  7.3950e-02]],\n",
       "              \n",
       "                       [[-4.1184e-02,  8.7218e-02,  1.5150e-02],\n",
       "                        [ 4.1869e-04,  4.1093e-03, -1.8623e-02],\n",
       "                        [ 9.8683e-02,  4.5784e-03,  6.4564e-02]],\n",
       "              \n",
       "                       [[-8.8967e-02, -5.4309e-02,  1.1852e-02],\n",
       "                        [ 8.4169e-02,  5.0184e-02,  2.0076e-02],\n",
       "                        [-1.0414e-01,  1.9816e-03, -6.9581e-02]],\n",
       "              \n",
       "                       [[-9.0006e-02,  1.4414e-02, -6.6693e-02],\n",
       "                        [ 9.5674e-02, -5.7294e-02,  3.3970e-02],\n",
       "                        [ 6.1871e-02, -8.1928e-02,  5.3946e-02]],\n",
       "              \n",
       "                       [[-1.4114e-02,  5.4619e-02,  1.0201e-01],\n",
       "                        [-4.4922e-02, -4.5653e-02,  8.3753e-02],\n",
       "                        [ 1.1722e-02, -1.0513e-02,  7.9971e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0928e-02, -5.2047e-03,  7.2403e-02],\n",
       "                        [ 4.1195e-02, -6.8180e-02,  2.7398e-02],\n",
       "                        [-8.0368e-02, -5.7245e-02,  6.7779e-02]],\n",
       "              \n",
       "                       [[-2.8093e-02, -5.3691e-02,  7.4717e-03],\n",
       "                        [ 2.5759e-02, -6.5524e-02, -7.1084e-02],\n",
       "                        [-1.0209e-01,  2.7236e-02, -6.8013e-02]],\n",
       "              \n",
       "                       [[ 8.0331e-03, -2.3576e-02, -6.8923e-02],\n",
       "                        [-3.3636e-02, -8.1027e-02, -5.5797e-02],\n",
       "                        [-3.2857e-03, -9.0116e-02, -9.2447e-02]],\n",
       "              \n",
       "                       [[ 7.8958e-02,  9.9188e-03, -4.6618e-02],\n",
       "                        [-3.5047e-03,  7.8168e-02, -8.7939e-02],\n",
       "                        [-5.5886e-02, -7.6226e-02, -7.6634e-03]],\n",
       "              \n",
       "                       [[-3.6274e-03, -8.2146e-02,  7.3163e-02],\n",
       "                        [-8.0946e-02,  9.8414e-02, -7.2560e-02],\n",
       "                        [-1.4446e-02,  1.9710e-02, -4.6852e-02]],\n",
       "              \n",
       "                       [[ 9.6939e-02, -7.2673e-02, -5.8427e-03],\n",
       "                        [-7.7398e-02,  2.9261e-02,  8.9871e-02],\n",
       "                        [ 9.7776e-02,  1.2514e-02, -5.2773e-02]],\n",
       "              \n",
       "                       [[ 1.0244e-01,  7.8667e-03,  7.1317e-02],\n",
       "                        [-5.4751e-02, -4.8920e-02, -8.7504e-02],\n",
       "                        [ 9.6990e-02,  1.7486e-02, -7.5704e-02]],\n",
       "              \n",
       "                       [[ 9.0535e-03, -4.5211e-02,  5.2659e-03],\n",
       "                        [ 3.4988e-02, -5.2308e-02,  1.8394e-02],\n",
       "                        [-6.6553e-02,  2.0312e-02, -1.0178e-01]],\n",
       "              \n",
       "                       [[ 1.6797e-02,  1.0473e-01,  9.7094e-02],\n",
       "                        [ 3.8451e-02,  7.7563e-02,  1.0248e-01],\n",
       "                        [ 2.9870e-02,  3.5156e-02,  1.3707e-02]],\n",
       "              \n",
       "                       [[ 9.3322e-02,  9.0551e-02, -4.9570e-02],\n",
       "                        [-4.3333e-03, -5.3110e-02,  3.7824e-02],\n",
       "                        [-1.0214e-01,  3.7301e-02, -2.8929e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8227e-02,  3.2899e-02, -5.2454e-02],\n",
       "                        [ 5.4687e-02,  4.4762e-02, -8.9602e-02],\n",
       "                        [ 1.0517e-01,  9.0731e-02,  6.5584e-02]],\n",
       "              \n",
       "                       [[-1.0699e-02,  3.7345e-02, -5.7028e-02],\n",
       "                        [-3.5818e-02,  4.9749e-02,  4.6925e-02],\n",
       "                        [ 4.1741e-02, -1.0053e-01,  8.7350e-02]],\n",
       "              \n",
       "                       [[-4.4028e-02,  9.1223e-02,  8.6852e-02],\n",
       "                        [ 3.9070e-02,  1.0502e-01,  6.0528e-02],\n",
       "                        [ 6.1821e-02, -3.5794e-02,  9.7766e-02]],\n",
       "              \n",
       "                       [[ 2.7627e-02,  6.2280e-02, -2.3834e-02],\n",
       "                        [ 7.6340e-02,  9.3509e-02, -8.0770e-02],\n",
       "                        [ 8.6415e-02, -6.9664e-02, -7.2571e-02]],\n",
       "              \n",
       "                       [[-8.8089e-02,  3.0459e-02, -7.9144e-02],\n",
       "                        [-3.9680e-02, -5.2988e-02,  2.8172e-02],\n",
       "                        [-1.0349e-01, -4.8324e-02,  7.7112e-04]],\n",
       "              \n",
       "                       [[ 9.4660e-03, -4.7605e-02,  3.7764e-02],\n",
       "                        [-6.9544e-02, -8.9270e-02, -1.4986e-02],\n",
       "                        [-5.6989e-02,  6.6443e-02, -7.2049e-02]],\n",
       "              \n",
       "                       [[-8.8494e-03,  4.3782e-02, -9.2311e-02],\n",
       "                        [ 8.1599e-02, -4.7895e-02, -2.8684e-02],\n",
       "                        [-6.4480e-02, -3.9279e-02, -4.0645e-02]],\n",
       "              \n",
       "                       [[-9.3801e-02,  3.6019e-02, -3.3768e-04],\n",
       "                        [ 1.0311e-01,  7.1117e-02,  9.1699e-02],\n",
       "                        [ 3.1014e-02,  5.5388e-02,  9.8704e-02]],\n",
       "              \n",
       "                       [[ 8.6545e-02, -8.0996e-02, -2.3636e-02],\n",
       "                        [-1.0166e-01,  3.9877e-03, -3.7229e-02],\n",
       "                        [ 9.1486e-02,  1.6666e-02,  1.1601e-03]],\n",
       "              \n",
       "                       [[-7.6248e-02, -8.2718e-02,  1.6594e-02],\n",
       "                        [-5.2376e-02, -4.8409e-02,  7.3938e-02],\n",
       "                        [-5.4952e-02, -4.6918e-02,  8.0934e-02]]]], device='cuda:0')),\n",
       "             ('conv_block_2.2.bias',\n",
       "              tensor([ 0.0412, -0.0599,  0.0319,  0.0531, -0.0936,  0.0197,  0.0241, -0.0041,\n",
       "                       0.1011, -0.0697], device='cuda:0')),\n",
       "             ('classifier.1.weight',\n",
       "              tensor([], device='cuda:0', size=(10, 0))),\n",
       "             ('classifier.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4beac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64, 64])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a single conv2d layer\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=10,\n",
    "                       kernel_size=3,\n",
    "                       stride=1,\n",
    "                       padding=1)\n",
    "\n",
    "# Pass the data through the convolutional layer\n",
    "conv_output = conv_layer(test_image)\n",
    "conv_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e40263",
   "metadata": {},
   "source": [
    "### 7.2 Stepping through `nn.MaxPool2d()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e980709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image original shape: torch.Size([3, 64, 64])\n",
      "Test image with unsqueezed dimension: torch.Size([1, 3, 64, 64])\n",
      "Shape after going through conv_layer(): torch.Size([1, 10, 64, 64])\n",
      "Shape after going through conv_layer() and max_pool_layer(): torch.Size([1, 10, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Print out original image shape\n",
    "print(f\"Test image original shape: {test_image.shape}\")\n",
    "print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(0).shape}\")\n",
    "\n",
    "# Create a smaple nn.MaxPool2d layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# Pass data through just the conv_layer\n",
    "test_image_through_conv = conv_layer(test_image.unsqueeze(0))\n",
    "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
    "\n",
    "# Pass data through the max pool layer\n",
    "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
    "print(f\"Shape after going through conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780916d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
